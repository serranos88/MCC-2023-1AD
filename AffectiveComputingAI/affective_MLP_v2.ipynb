{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga en memoria el dataframe\n",
    "df = pd.read_pickle('affective_dataset_v2.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>face_closeup</th>\n",
       "      <th>face_landmarks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[165, 166, 164, 167, 167, 166, 167, 167, 167,...</td>\n",
       "      <td>[[161, 160, 161, 161, 161, 161, 161, 160, 99, ...</td>\n",
       "      <td>[[62, 83], [62, 88], [63, 93], [63, 97], [64, ...</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[165, 166, 165, 166, 167, 167, 167, 167, 167,...</td>\n",
       "      <td>[[160, 161, 160, 161, 161, 162, 161, 162, 132,...</td>\n",
       "      <td>[[62, 83], [62, 88], [63, 93], [63, 97], [64, ...</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[165, 165, 165, 166, 167, 166, 166, 167, 167,...</td>\n",
       "      <td>[[160, 161, 161, 60, 36, 76, 88, 88, 92, 102, ...</td>\n",
       "      <td>[[63, 82], [63, 87], [63, 91], [63, 96], [65, ...</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[165, 166, 165, 165, 166, 167, 167, 167, 167,...</td>\n",
       "      <td>[[160, 161, 160, 45, 42, 81, 88, 88, 92, 101, ...</td>\n",
       "      <td>[[63, 83], [63, 87], [63, 92], [64, 97], [65, ...</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[165, 166, 166, 166, 166, 167, 166, 166, 167,...</td>\n",
       "      <td>[[160, 160, 160, 41, 43, 81, 88, 88, 92, 102, ...</td>\n",
       "      <td>[[63, 83], [63, 88], [63, 92], [64, 97], [65, ...</td>\n",
       "      <td>bored</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image  \\\n",
       "0  [[165, 166, 164, 167, 167, 166, 167, 167, 167,...   \n",
       "1  [[165, 166, 165, 166, 167, 167, 167, 167, 167,...   \n",
       "2  [[165, 165, 165, 166, 167, 166, 166, 167, 167,...   \n",
       "3  [[165, 166, 165, 165, 166, 167, 167, 167, 167,...   \n",
       "4  [[165, 166, 166, 166, 166, 167, 166, 166, 167,...   \n",
       "\n",
       "                                        face_closeup  \\\n",
       "0  [[161, 160, 161, 161, 161, 161, 161, 160, 99, ...   \n",
       "1  [[160, 161, 160, 161, 161, 162, 161, 162, 132,...   \n",
       "2  [[160, 161, 161, 60, 36, 76, 88, 88, 92, 102, ...   \n",
       "3  [[160, 161, 160, 45, 42, 81, 88, 88, 92, 101, ...   \n",
       "4  [[160, 160, 160, 41, 43, 81, 88, 88, 92, 102, ...   \n",
       "\n",
       "                                      face_landmarks  label  \n",
       "0  [[62, 83], [62, 88], [63, 93], [63, 97], [64, ...  bored  \n",
       "1  [[62, 83], [62, 88], [63, 93], [63, 97], [64, ...  bored  \n",
       "2  [[63, 82], [63, 87], [63, 91], [63, 96], [65, ...  bored  \n",
       "3  [[63, 83], [63, 87], [63, 92], [64, 97], [65, ...  bored  \n",
       "4  [[63, 83], [63, 88], [63, 92], [64, 97], [65, ...  bored  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "#print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['face_landmarks'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5023, 144, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['bored' 'engaged' 'excited' 'focused' 'interested' 'relaxed']\n",
      "Encoded labels: ['bored' 'engaged' 'excited' 'focused' 'interested' 'relaxed']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original labels:\", df['label'].unique())\n",
    "print(\"Encoded labels:\", label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "# Entrada del modelo\n",
    "inputs = Input(shape=(144, 2))\n",
    "\n",
    "# Aplanar los datos de entrada\n",
    "flatten = Flatten()(inputs)\n",
    "\n",
    "# Capas ocultas\n",
    "dense1 = Dense(600, activation='relu')(flatten)\n",
    "dense2 = Dense(480, activation='relu')(dense1)\n",
    "dense3 = Dense(64, activation='relu')(dense2)\n",
    "\n",
    "\n",
    "# Capa de salida\n",
    "outputs = Dense(len(label_encoder.classes_), activation='softmax')(dense3)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') >= 0.65:\n",
    "            print(\"\\nReached 60% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "back = myCallback() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      " 5/88 [>.............................] - ETA: 1s - loss: 49.7499 - accuracy: 0.3625  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_train_batch_end` time: 0.0087s). Check your callbacks.\n",
      "88/88 [==============================] - 3s 10ms/step - loss: 8.2896 - accuracy: 0.3094 - val_loss: 1.7643 - val_accuracy: 0.2685\n",
      "Epoch 2/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.7701 - accuracy: 0.3506 - val_loss: 1.5267 - val_accuracy: 0.4332\n",
      "Epoch 3/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.9693 - accuracy: 0.3343 - val_loss: 1.2911 - val_accuracy: 0.4347\n",
      "Epoch 4/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.4564 - accuracy: 0.3755 - val_loss: 1.3818 - val_accuracy: 0.3949\n",
      "Epoch 5/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.4038 - accuracy: 0.3898 - val_loss: 1.3962 - val_accuracy: 0.3963\n",
      "Epoch 6/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3874 - accuracy: 0.3745 - val_loss: 1.2794 - val_accuracy: 0.4077\n",
      "Epoch 7/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3227 - accuracy: 0.4065 - val_loss: 1.2658 - val_accuracy: 0.3949\n",
      "Epoch 8/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3224 - accuracy: 0.3979 - val_loss: 1.2584 - val_accuracy: 0.4616\n",
      "Epoch 9/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.3016 - accuracy: 0.4054 - val_loss: 1.2590 - val_accuracy: 0.4148\n",
      "Epoch 10/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2935 - accuracy: 0.4022 - val_loss: 1.2294 - val_accuracy: 0.4077\n",
      "Epoch 11/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2654 - accuracy: 0.4299 - val_loss: 1.2699 - val_accuracy: 0.3935\n",
      "Epoch 12/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2850 - accuracy: 0.4203 - val_loss: 1.2489 - val_accuracy: 0.3892\n",
      "Epoch 13/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.3010 - accuracy: 0.3930 - val_loss: 1.2484 - val_accuracy: 0.4347\n",
      "Epoch 14/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2858 - accuracy: 0.4100 - val_loss: 1.2358 - val_accuracy: 0.4176\n",
      "Epoch 15/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3042 - accuracy: 0.3890 - val_loss: 1.2683 - val_accuracy: 0.3892\n",
      "Epoch 16/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2984 - accuracy: 0.4058 - val_loss: 1.2970 - val_accuracy: 0.4205\n",
      "Epoch 17/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3085 - accuracy: 0.4001 - val_loss: 1.2475 - val_accuracy: 0.4304\n",
      "Epoch 18/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2989 - accuracy: 0.4093 - val_loss: 1.3241 - val_accuracy: 0.3864\n",
      "Epoch 19/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.3160 - accuracy: 0.3869 - val_loss: 1.2748 - val_accuracy: 0.4048\n",
      "Epoch 20/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3005 - accuracy: 0.3994 - val_loss: 1.2646 - val_accuracy: 0.4389\n",
      "Epoch 21/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.3012 - accuracy: 0.4093 - val_loss: 1.2838 - val_accuracy: 0.4631\n",
      "Epoch 22/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.3108 - accuracy: 0.4047 - val_loss: 1.2640 - val_accuracy: 0.3793\n",
      "Epoch 23/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.3021 - accuracy: 0.4040 - val_loss: 1.2846 - val_accuracy: 0.3736\n",
      "Epoch 24/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3161 - accuracy: 0.3926 - val_loss: 1.2963 - val_accuracy: 0.3750\n",
      "Epoch 25/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2920 - accuracy: 0.4090 - val_loss: 1.2982 - val_accuracy: 0.4247\n",
      "Epoch 26/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2920 - accuracy: 0.4175 - val_loss: 1.2500 - val_accuracy: 0.4545\n",
      "Epoch 27/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2892 - accuracy: 0.4061 - val_loss: 1.2992 - val_accuracy: 0.3750\n",
      "Epoch 28/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2874 - accuracy: 0.4015 - val_loss: 1.2597 - val_accuracy: 0.4503\n",
      "Epoch 29/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2815 - accuracy: 0.4086 - val_loss: 1.2435 - val_accuracy: 0.4560\n",
      "Epoch 30/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2845 - accuracy: 0.4125 - val_loss: 1.2841 - val_accuracy: 0.3565\n",
      "Epoch 31/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2947 - accuracy: 0.4079 - val_loss: 1.2662 - val_accuracy: 0.4247\n",
      "Epoch 32/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2814 - accuracy: 0.4150 - val_loss: 1.2277 - val_accuracy: 0.4588\n",
      "Epoch 33/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2798 - accuracy: 0.4186 - val_loss: 1.2392 - val_accuracy: 0.4162\n",
      "Epoch 34/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2731 - accuracy: 0.4164 - val_loss: 1.2494 - val_accuracy: 0.4006\n",
      "Epoch 35/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2819 - accuracy: 0.4235 - val_loss: 1.2444 - val_accuracy: 0.4276\n",
      "Epoch 36/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2836 - accuracy: 0.4282 - val_loss: 1.2315 - val_accuracy: 0.4347\n",
      "Epoch 37/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2711 - accuracy: 0.4339 - val_loss: 1.2518 - val_accuracy: 0.4176\n",
      "Epoch 38/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2939 - accuracy: 0.4097 - val_loss: 1.2820 - val_accuracy: 0.4276\n",
      "Epoch 39/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2766 - accuracy: 0.4232 - val_loss: 1.3426 - val_accuracy: 0.3480\n",
      "Epoch 40/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.3024 - accuracy: 0.3947 - val_loss: 1.2511 - val_accuracy: 0.4261\n",
      "Epoch 41/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2773 - accuracy: 0.4264 - val_loss: 1.3301 - val_accuracy: 0.3878\n",
      "Epoch 42/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2779 - accuracy: 0.4314 - val_loss: 1.2479 - val_accuracy: 0.4588\n",
      "Epoch 43/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2680 - accuracy: 0.4349 - val_loss: 1.2184 - val_accuracy: 0.4702\n",
      "Epoch 44/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2730 - accuracy: 0.4307 - val_loss: 1.2387 - val_accuracy: 0.4361\n",
      "Epoch 45/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2774 - accuracy: 0.4285 - val_loss: 1.2336 - val_accuracy: 0.4602\n",
      "Epoch 46/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2742 - accuracy: 0.4282 - val_loss: 1.2288 - val_accuracy: 0.4176\n",
      "Epoch 47/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2885 - accuracy: 0.4079 - val_loss: 1.2487 - val_accuracy: 0.3977\n",
      "Epoch 48/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2770 - accuracy: 0.4349 - val_loss: 1.2395 - val_accuracy: 0.4631\n",
      "Epoch 49/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2901 - accuracy: 0.4086 - val_loss: 1.2370 - val_accuracy: 0.4091\n",
      "Epoch 50/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2804 - accuracy: 0.4189 - val_loss: 1.2330 - val_accuracy: 0.4616\n",
      "Epoch 51/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2831 - accuracy: 0.4179 - val_loss: 1.2469 - val_accuracy: 0.4176\n",
      "Epoch 52/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2757 - accuracy: 0.4267 - val_loss: 1.2267 - val_accuracy: 0.4673\n",
      "Epoch 53/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2818 - accuracy: 0.4296 - val_loss: 1.2591 - val_accuracy: 0.4517\n",
      "Epoch 54/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2780 - accuracy: 0.4289 - val_loss: 1.2461 - val_accuracy: 0.4716\n",
      "Epoch 55/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2746 - accuracy: 0.4310 - val_loss: 1.2499 - val_accuracy: 0.4318\n",
      "Epoch 56/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2679 - accuracy: 0.4356 - val_loss: 1.2264 - val_accuracy: 0.4574\n",
      "Epoch 57/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2674 - accuracy: 0.4392 - val_loss: 1.2504 - val_accuracy: 0.4190\n",
      "Epoch 58/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2765 - accuracy: 0.4285 - val_loss: 1.2181 - val_accuracy: 0.4631\n",
      "Epoch 59/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2638 - accuracy: 0.4385 - val_loss: 1.2424 - val_accuracy: 0.4347\n",
      "Epoch 60/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2777 - accuracy: 0.4189 - val_loss: 1.2113 - val_accuracy: 0.4688\n",
      "Epoch 61/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2698 - accuracy: 0.4395 - val_loss: 1.2343 - val_accuracy: 0.4375\n",
      "Epoch 62/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2628 - accuracy: 0.4403 - val_loss: 1.2279 - val_accuracy: 0.4560\n",
      "Epoch 63/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2725 - accuracy: 0.4324 - val_loss: 1.2187 - val_accuracy: 0.4290\n",
      "Epoch 64/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2673 - accuracy: 0.4346 - val_loss: 1.2181 - val_accuracy: 0.4418\n",
      "Epoch 65/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2740 - accuracy: 0.4356 - val_loss: 1.2258 - val_accuracy: 0.4744\n",
      "Epoch 66/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2563 - accuracy: 0.4506 - val_loss: 1.2086 - val_accuracy: 0.4503\n",
      "Epoch 67/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2783 - accuracy: 0.4317 - val_loss: 1.2119 - val_accuracy: 0.4531\n",
      "Epoch 68/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2562 - accuracy: 0.4456 - val_loss: 1.2098 - val_accuracy: 0.4588\n",
      "Epoch 69/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2470 - accuracy: 0.4555 - val_loss: 1.2145 - val_accuracy: 0.4531\n",
      "Epoch 70/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2691 - accuracy: 0.4342 - val_loss: 1.2128 - val_accuracy: 0.4744\n",
      "Epoch 71/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2623 - accuracy: 0.4420 - val_loss: 1.2328 - val_accuracy: 0.4205\n",
      "Epoch 72/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2575 - accuracy: 0.4424 - val_loss: 1.2217 - val_accuracy: 0.4716\n",
      "Epoch 73/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2585 - accuracy: 0.4499 - val_loss: 1.2687 - val_accuracy: 0.3949\n",
      "Epoch 74/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2849 - accuracy: 0.4278 - val_loss: 1.2495 - val_accuracy: 0.4261\n",
      "Epoch 75/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2618 - accuracy: 0.4374 - val_loss: 1.2083 - val_accuracy: 0.4716\n",
      "Epoch 76/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2516 - accuracy: 0.4406 - val_loss: 1.2267 - val_accuracy: 0.4332\n",
      "Epoch 77/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2763 - accuracy: 0.4321 - val_loss: 1.3011 - val_accuracy: 0.3864\n",
      "Epoch 78/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3184 - accuracy: 0.3986 - val_loss: 1.2983 - val_accuracy: 0.3864\n",
      "Epoch 79/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3166 - accuracy: 0.3926 - val_loss: 1.3016 - val_accuracy: 0.3864\n",
      "Epoch 80/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.3120 - accuracy: 0.3787 - val_loss: 1.2854 - val_accuracy: 0.3835\n",
      "Epoch 81/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3077 - accuracy: 0.3791 - val_loss: 1.3135 - val_accuracy: 0.3878\n",
      "Epoch 82/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.3055 - accuracy: 0.3862 - val_loss: 1.2807 - val_accuracy: 0.3864\n",
      "Epoch 83/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2903 - accuracy: 0.4161 - val_loss: 1.2886 - val_accuracy: 0.3693\n",
      "Epoch 84/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3252 - accuracy: 0.4036 - val_loss: 2.9213 - val_accuracy: 0.3537\n",
      "Epoch 85/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.6072 - accuracy: 0.3823 - val_loss: 1.2645 - val_accuracy: 0.3849\n",
      "Epoch 86/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2919 - accuracy: 0.4093 - val_loss: 1.2868 - val_accuracy: 0.4105\n",
      "Epoch 87/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2808 - accuracy: 0.4118 - val_loss: 1.2502 - val_accuracy: 0.4233\n",
      "Epoch 88/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2793 - accuracy: 0.4232 - val_loss: 1.2478 - val_accuracy: 0.4091\n",
      "Epoch 89/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2726 - accuracy: 0.4136 - val_loss: 1.2487 - val_accuracy: 0.4119\n",
      "Epoch 90/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2806 - accuracy: 0.4218 - val_loss: 1.2537 - val_accuracy: 0.3935\n",
      "Epoch 91/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2754 - accuracy: 0.4139 - val_loss: 1.2424 - val_accuracy: 0.4389\n",
      "Epoch 92/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2752 - accuracy: 0.4239 - val_loss: 1.2411 - val_accuracy: 0.4233\n",
      "Epoch 93/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2690 - accuracy: 0.4282 - val_loss: 1.2511 - val_accuracy: 0.3920\n",
      "Epoch 94/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2780 - accuracy: 0.4314 - val_loss: 1.2423 - val_accuracy: 0.4375\n",
      "Epoch 95/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2780 - accuracy: 0.4179 - val_loss: 1.2598 - val_accuracy: 0.4077\n",
      "Epoch 96/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2715 - accuracy: 0.4367 - val_loss: 1.2695 - val_accuracy: 0.4148\n",
      "Epoch 97/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2792 - accuracy: 0.4257 - val_loss: 1.2395 - val_accuracy: 0.4361\n",
      "Epoch 98/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2726 - accuracy: 0.4164 - val_loss: 1.2687 - val_accuracy: 0.4134\n",
      "Epoch 99/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2776 - accuracy: 0.4018 - val_loss: 1.2695 - val_accuracy: 0.4105\n",
      "Epoch 100/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2775 - accuracy: 0.4225 - val_loss: 1.2837 - val_accuracy: 0.3736\n",
      "Epoch 101/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2816 - accuracy: 0.4139 - val_loss: 1.2376 - val_accuracy: 0.4446\n",
      "Epoch 102/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2741 - accuracy: 0.4211 - val_loss: 1.2628 - val_accuracy: 0.3835\n",
      "Epoch 103/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2681 - accuracy: 0.4250 - val_loss: 1.2660 - val_accuracy: 0.3821\n",
      "Epoch 104/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2708 - accuracy: 0.4186 - val_loss: 1.2398 - val_accuracy: 0.4545\n",
      "Epoch 105/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2655 - accuracy: 0.4246 - val_loss: 1.2419 - val_accuracy: 0.4318\n",
      "Epoch 106/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2683 - accuracy: 0.4314 - val_loss: 1.2386 - val_accuracy: 0.4233\n",
      "Epoch 107/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2651 - accuracy: 0.4331 - val_loss: 1.2265 - val_accuracy: 0.4659\n",
      "Epoch 108/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2736 - accuracy: 0.4171 - val_loss: 1.2408 - val_accuracy: 0.4347\n",
      "Epoch 109/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2612 - accuracy: 0.4292 - val_loss: 1.2283 - val_accuracy: 0.4702\n",
      "Epoch 110/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2636 - accuracy: 0.4342 - val_loss: 1.2902 - val_accuracy: 0.3977\n",
      "Epoch 111/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2595 - accuracy: 0.4303 - val_loss: 1.2319 - val_accuracy: 0.4318\n",
      "Epoch 112/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2572 - accuracy: 0.4481 - val_loss: 1.2313 - val_accuracy: 0.4432\n",
      "Epoch 113/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2752 - accuracy: 0.4299 - val_loss: 1.2533 - val_accuracy: 0.4545\n",
      "Epoch 114/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2716 - accuracy: 0.4456 - val_loss: 1.2546 - val_accuracy: 0.4389\n",
      "Epoch 115/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2949 - accuracy: 0.3830 - val_loss: 1.2902 - val_accuracy: 0.4148\n",
      "Epoch 116/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2892 - accuracy: 0.4008 - val_loss: 1.2718 - val_accuracy: 0.4020\n",
      "Epoch 117/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2680 - accuracy: 0.4285 - val_loss: 1.2524 - val_accuracy: 0.4119\n",
      "Epoch 118/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2750 - accuracy: 0.4058 - val_loss: 1.2234 - val_accuracy: 0.4574\n",
      "Epoch 119/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2613 - accuracy: 0.4346 - val_loss: 1.2710 - val_accuracy: 0.4247\n",
      "Epoch 120/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2557 - accuracy: 0.4534 - val_loss: 1.2289 - val_accuracy: 0.4460\n",
      "Epoch 121/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2654 - accuracy: 0.4403 - val_loss: 1.3197 - val_accuracy: 0.3523\n",
      "Epoch 122/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2924 - accuracy: 0.4050 - val_loss: 1.2777 - val_accuracy: 0.3679\n",
      "Epoch 123/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2689 - accuracy: 0.4218 - val_loss: 1.2861 - val_accuracy: 0.3835\n",
      "Epoch 124/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2543 - accuracy: 0.4438 - val_loss: 1.2410 - val_accuracy: 0.4091\n",
      "Epoch 125/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2645 - accuracy: 0.4324 - val_loss: 1.2266 - val_accuracy: 0.4290\n",
      "Epoch 126/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2514 - accuracy: 0.4442 - val_loss: 1.2217 - val_accuracy: 0.4531\n",
      "Epoch 127/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2462 - accuracy: 0.4463 - val_loss: 1.2485 - val_accuracy: 0.4347\n",
      "Epoch 128/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2676 - accuracy: 0.4289 - val_loss: 1.2204 - val_accuracy: 0.4545\n",
      "Epoch 129/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2500 - accuracy: 0.4495 - val_loss: 1.2145 - val_accuracy: 0.4645\n",
      "Epoch 130/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2716 - accuracy: 0.4285 - val_loss: 1.2170 - val_accuracy: 0.4631\n",
      "Epoch 131/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2593 - accuracy: 0.4378 - val_loss: 1.2176 - val_accuracy: 0.4574\n",
      "Epoch 132/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2628 - accuracy: 0.4395 - val_loss: 1.2504 - val_accuracy: 0.4105\n",
      "Epoch 133/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2596 - accuracy: 0.4442 - val_loss: 1.2198 - val_accuracy: 0.4659\n",
      "Epoch 134/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2590 - accuracy: 0.4317 - val_loss: 1.2216 - val_accuracy: 0.4574\n",
      "Epoch 135/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2792 - accuracy: 0.4111 - val_loss: 1.2426 - val_accuracy: 0.4006\n",
      "Epoch 136/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2567 - accuracy: 0.4342 - val_loss: 1.2259 - val_accuracy: 0.4389\n",
      "Epoch 137/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2715 - accuracy: 0.4257 - val_loss: 1.2208 - val_accuracy: 0.4645\n",
      "Epoch 138/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2479 - accuracy: 0.4488 - val_loss: 1.2253 - val_accuracy: 0.4375\n",
      "Epoch 139/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2533 - accuracy: 0.4470 - val_loss: 1.2260 - val_accuracy: 0.4588\n",
      "Epoch 140/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2654 - accuracy: 0.4346 - val_loss: 1.2519 - val_accuracy: 0.4105\n",
      "Epoch 141/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2539 - accuracy: 0.4392 - val_loss: 1.2149 - val_accuracy: 0.4531\n",
      "Epoch 142/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2714 - accuracy: 0.4317 - val_loss: 1.2262 - val_accuracy: 0.4403\n",
      "Epoch 143/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2811 - accuracy: 0.4196 - val_loss: 1.2432 - val_accuracy: 0.4162\n",
      "Epoch 144/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2531 - accuracy: 0.4463 - val_loss: 1.2321 - val_accuracy: 0.4446\n",
      "Epoch 145/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2407 - accuracy: 0.4463 - val_loss: 1.2739 - val_accuracy: 0.4134\n",
      "Epoch 146/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2794 - accuracy: 0.4150 - val_loss: 1.2831 - val_accuracy: 0.3878\n",
      "Epoch 147/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2488 - accuracy: 0.4385 - val_loss: 1.2812 - val_accuracy: 0.4190\n",
      "Epoch 148/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2551 - accuracy: 0.4356 - val_loss: 1.2532 - val_accuracy: 0.4176\n",
      "Epoch 149/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2514 - accuracy: 0.4395 - val_loss: 1.2266 - val_accuracy: 0.4233\n",
      "Epoch 150/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2513 - accuracy: 0.4520 - val_loss: 1.2183 - val_accuracy: 0.4545\n",
      "Epoch 151/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2441 - accuracy: 0.4445 - val_loss: 1.2285 - val_accuracy: 0.4403\n",
      "Epoch 152/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2435 - accuracy: 0.4467 - val_loss: 1.2297 - val_accuracy: 0.4403\n",
      "Epoch 153/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2367 - accuracy: 0.4509 - val_loss: 1.2282 - val_accuracy: 0.4375\n",
      "Epoch 154/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2401 - accuracy: 0.4502 - val_loss: 1.2069 - val_accuracy: 0.4574\n",
      "Epoch 155/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2456 - accuracy: 0.4523 - val_loss: 1.2690 - val_accuracy: 0.4020\n",
      "Epoch 156/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2655 - accuracy: 0.4282 - val_loss: 1.2928 - val_accuracy: 0.3977\n",
      "Epoch 157/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2467 - accuracy: 0.4488 - val_loss: 1.2433 - val_accuracy: 0.4247\n",
      "Epoch 158/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2588 - accuracy: 0.4278 - val_loss: 1.2115 - val_accuracy: 0.4418\n",
      "Epoch 159/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2484 - accuracy: 0.4452 - val_loss: 1.2207 - val_accuracy: 0.4460\n",
      "Epoch 160/800\n",
      "88/88 [==============================] - 1s 11ms/step - loss: 1.2473 - accuracy: 0.4427 - val_loss: 1.2426 - val_accuracy: 0.4403\n",
      "Epoch 161/800\n",
      "88/88 [==============================] - 1s 10ms/step - loss: 1.2264 - accuracy: 0.4552 - val_loss: 1.2277 - val_accuracy: 0.4560\n",
      "Epoch 162/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2478 - accuracy: 0.4399 - val_loss: 1.3052 - val_accuracy: 0.4006\n",
      "Epoch 163/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2513 - accuracy: 0.4438 - val_loss: 1.2335 - val_accuracy: 0.4290\n",
      "Epoch 164/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2567 - accuracy: 0.4413 - val_loss: 1.2376 - val_accuracy: 0.3935\n",
      "Epoch 165/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2408 - accuracy: 0.4467 - val_loss: 1.2204 - val_accuracy: 0.4389\n",
      "Epoch 166/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2269 - accuracy: 0.4566 - val_loss: 1.2479 - val_accuracy: 0.4276\n",
      "Epoch 167/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2534 - accuracy: 0.4488 - val_loss: 1.2485 - val_accuracy: 0.4432\n",
      "Epoch 168/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2416 - accuracy: 0.4435 - val_loss: 1.2118 - val_accuracy: 0.4474\n",
      "Epoch 169/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2299 - accuracy: 0.4484 - val_loss: 1.2165 - val_accuracy: 0.4574\n",
      "Epoch 170/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2288 - accuracy: 0.4612 - val_loss: 1.2146 - val_accuracy: 0.4531\n",
      "Epoch 171/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2379 - accuracy: 0.4452 - val_loss: 1.2072 - val_accuracy: 0.4474\n",
      "Epoch 172/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2488 - accuracy: 0.4381 - val_loss: 1.2577 - val_accuracy: 0.4134\n",
      "Epoch 173/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2419 - accuracy: 0.4456 - val_loss: 1.2085 - val_accuracy: 0.4432\n",
      "Epoch 174/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2325 - accuracy: 0.4516 - val_loss: 1.2569 - val_accuracy: 0.4375\n",
      "Epoch 175/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2447 - accuracy: 0.4435 - val_loss: 1.2120 - val_accuracy: 0.4588\n",
      "Epoch 176/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2365 - accuracy: 0.4523 - val_loss: 1.2089 - val_accuracy: 0.4489\n",
      "Epoch 177/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2887 - accuracy: 0.4118 - val_loss: 1.2769 - val_accuracy: 0.3821\n",
      "Epoch 178/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2966 - accuracy: 0.3930 - val_loss: 1.2683 - val_accuracy: 0.4020\n",
      "Epoch 179/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2902 - accuracy: 0.3954 - val_loss: 1.2716 - val_accuracy: 0.3963\n",
      "Epoch 180/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2839 - accuracy: 0.4047 - val_loss: 1.2666 - val_accuracy: 0.3920\n",
      "Epoch 181/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2826 - accuracy: 0.4050 - val_loss: 1.2578 - val_accuracy: 0.4034\n",
      "Epoch 182/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2766 - accuracy: 0.4136 - val_loss: 1.2668 - val_accuracy: 0.3963\n",
      "Epoch 183/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2758 - accuracy: 0.4239 - val_loss: 1.2533 - val_accuracy: 0.4162\n",
      "Epoch 184/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2555 - accuracy: 0.4438 - val_loss: 1.2265 - val_accuracy: 0.4403\n",
      "Epoch 185/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2657 - accuracy: 0.4353 - val_loss: 1.2462 - val_accuracy: 0.4162\n",
      "Epoch 186/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2536 - accuracy: 0.4499 - val_loss: 1.2323 - val_accuracy: 0.4361\n",
      "Epoch 187/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2547 - accuracy: 0.4449 - val_loss: 1.2264 - val_accuracy: 0.4361\n",
      "Epoch 188/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2571 - accuracy: 0.4452 - val_loss: 1.2805 - val_accuracy: 0.3949\n",
      "Epoch 189/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2494 - accuracy: 0.4499 - val_loss: 1.2563 - val_accuracy: 0.3878\n",
      "Epoch 190/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2641 - accuracy: 0.4250 - val_loss: 1.3252 - val_accuracy: 0.4176\n",
      "Epoch 191/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2748 - accuracy: 0.4371 - val_loss: 1.2233 - val_accuracy: 0.4446\n",
      "Epoch 192/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2425 - accuracy: 0.4467 - val_loss: 1.2198 - val_accuracy: 0.4474\n",
      "Epoch 193/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2498 - accuracy: 0.4363 - val_loss: 1.2112 - val_accuracy: 0.4560\n",
      "Epoch 194/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2436 - accuracy: 0.4499 - val_loss: 1.2104 - val_accuracy: 0.4560\n",
      "Epoch 195/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2402 - accuracy: 0.4413 - val_loss: 1.2552 - val_accuracy: 0.4318\n",
      "Epoch 196/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2452 - accuracy: 0.4474 - val_loss: 1.2353 - val_accuracy: 0.4276\n",
      "Epoch 197/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2529 - accuracy: 0.4417 - val_loss: 1.2745 - val_accuracy: 0.4006\n",
      "Epoch 198/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2497 - accuracy: 0.4513 - val_loss: 1.2212 - val_accuracy: 0.4389\n",
      "Epoch 199/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2450 - accuracy: 0.4456 - val_loss: 1.2145 - val_accuracy: 0.4574\n",
      "Epoch 200/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2338 - accuracy: 0.4495 - val_loss: 1.2448 - val_accuracy: 0.4432\n",
      "Epoch 201/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2568 - accuracy: 0.4392 - val_loss: 1.2264 - val_accuracy: 0.4347\n",
      "Epoch 202/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2576 - accuracy: 0.4296 - val_loss: 1.2726 - val_accuracy: 0.4148\n",
      "Epoch 203/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2530 - accuracy: 0.4403 - val_loss: 1.2202 - val_accuracy: 0.4517\n",
      "Epoch 204/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2418 - accuracy: 0.4470 - val_loss: 1.2710 - val_accuracy: 0.4006\n",
      "Epoch 205/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2426 - accuracy: 0.4399 - val_loss: 1.2277 - val_accuracy: 0.4460\n",
      "Epoch 206/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2389 - accuracy: 0.4502 - val_loss: 1.2119 - val_accuracy: 0.4517\n",
      "Epoch 207/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2399 - accuracy: 0.4424 - val_loss: 1.2182 - val_accuracy: 0.4432\n",
      "Epoch 208/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2522 - accuracy: 0.4381 - val_loss: 1.2239 - val_accuracy: 0.4347\n",
      "Epoch 209/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2318 - accuracy: 0.4584 - val_loss: 1.2295 - val_accuracy: 0.4432\n",
      "Epoch 210/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2407 - accuracy: 0.4417 - val_loss: 1.2275 - val_accuracy: 0.4347\n",
      "Epoch 211/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2612 - accuracy: 0.4363 - val_loss: 1.2379 - val_accuracy: 0.4261\n",
      "Epoch 212/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2611 - accuracy: 0.4367 - val_loss: 1.2486 - val_accuracy: 0.4247\n",
      "Epoch 213/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2310 - accuracy: 0.4534 - val_loss: 1.2246 - val_accuracy: 0.4446\n",
      "Epoch 214/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2263 - accuracy: 0.4566 - val_loss: 1.2091 - val_accuracy: 0.4474\n",
      "Epoch 215/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2581 - accuracy: 0.4356 - val_loss: 1.2258 - val_accuracy: 0.4290\n",
      "Epoch 216/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2233 - accuracy: 0.4555 - val_loss: 1.2123 - val_accuracy: 0.4403\n",
      "Epoch 217/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2226 - accuracy: 0.4634 - val_loss: 1.2152 - val_accuracy: 0.4375\n",
      "Epoch 218/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2249 - accuracy: 0.4552 - val_loss: 1.2482 - val_accuracy: 0.4474\n",
      "Epoch 219/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2522 - accuracy: 0.4385 - val_loss: 1.2633 - val_accuracy: 0.4290\n",
      "Epoch 220/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2415 - accuracy: 0.4388 - val_loss: 1.2638 - val_accuracy: 0.4034\n",
      "Epoch 221/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2471 - accuracy: 0.4406 - val_loss: 1.2100 - val_accuracy: 0.4688\n",
      "Epoch 222/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2654 - accuracy: 0.4346 - val_loss: 1.2093 - val_accuracy: 0.4588\n",
      "Epoch 223/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2255 - accuracy: 0.4673 - val_loss: 1.2252 - val_accuracy: 0.4474\n",
      "Epoch 224/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2255 - accuracy: 0.4559 - val_loss: 1.2248 - val_accuracy: 0.4489\n",
      "Epoch 225/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2233 - accuracy: 0.4477 - val_loss: 1.2081 - val_accuracy: 0.4432\n",
      "Epoch 226/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2506 - accuracy: 0.4388 - val_loss: 1.2376 - val_accuracy: 0.4318\n",
      "Epoch 227/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2392 - accuracy: 0.4424 - val_loss: 1.2126 - val_accuracy: 0.4616\n",
      "Epoch 228/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2366 - accuracy: 0.4406 - val_loss: 1.2122 - val_accuracy: 0.4474\n",
      "Epoch 229/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2393 - accuracy: 0.4392 - val_loss: 1.3148 - val_accuracy: 0.3906\n",
      "Epoch 230/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2997 - accuracy: 0.3997 - val_loss: 1.2698 - val_accuracy: 0.4048\n",
      "Epoch 231/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2864 - accuracy: 0.4015 - val_loss: 1.2571 - val_accuracy: 0.3963\n",
      "Epoch 232/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2731 - accuracy: 0.4196 - val_loss: 1.2700 - val_accuracy: 0.3892\n",
      "Epoch 233/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2650 - accuracy: 0.4303 - val_loss: 1.2186 - val_accuracy: 0.4531\n",
      "Epoch 234/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2500 - accuracy: 0.4427 - val_loss: 1.2255 - val_accuracy: 0.4247\n",
      "Epoch 235/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2316 - accuracy: 0.4552 - val_loss: 1.2077 - val_accuracy: 0.4403\n",
      "Epoch 236/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2545 - accuracy: 0.4424 - val_loss: 1.2486 - val_accuracy: 0.4361\n",
      "Epoch 237/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2346 - accuracy: 0.4463 - val_loss: 1.2158 - val_accuracy: 0.4304\n",
      "Epoch 238/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2302 - accuracy: 0.4580 - val_loss: 1.2120 - val_accuracy: 0.4361\n",
      "Epoch 239/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2224 - accuracy: 0.4573 - val_loss: 1.2206 - val_accuracy: 0.4332\n",
      "Epoch 240/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2429 - accuracy: 0.4413 - val_loss: 1.2087 - val_accuracy: 0.4460\n",
      "Epoch 241/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2231 - accuracy: 0.4555 - val_loss: 1.2223 - val_accuracy: 0.4347\n",
      "Epoch 242/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2271 - accuracy: 0.4566 - val_loss: 1.2204 - val_accuracy: 0.4418\n",
      "Epoch 243/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2207 - accuracy: 0.4552 - val_loss: 1.2402 - val_accuracy: 0.4432\n",
      "Epoch 244/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2422 - accuracy: 0.4331 - val_loss: 1.2170 - val_accuracy: 0.4574\n",
      "Epoch 245/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2623 - accuracy: 0.4403 - val_loss: 1.2872 - val_accuracy: 0.3778\n",
      "Epoch 246/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2929 - accuracy: 0.3837 - val_loss: 1.2772 - val_accuracy: 0.3551\n",
      "Epoch 247/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2824 - accuracy: 0.4054 - val_loss: 1.2636 - val_accuracy: 0.3963\n",
      "Epoch 248/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2737 - accuracy: 0.4207 - val_loss: 1.2366 - val_accuracy: 0.4276\n",
      "Epoch 249/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2663 - accuracy: 0.4303 - val_loss: 1.2522 - val_accuracy: 0.4034\n",
      "Epoch 250/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2372 - accuracy: 0.4516 - val_loss: 1.2080 - val_accuracy: 0.4517\n",
      "Epoch 251/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2307 - accuracy: 0.4580 - val_loss: 1.2252 - val_accuracy: 0.4432\n",
      "Epoch 252/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2219 - accuracy: 0.4623 - val_loss: 1.2118 - val_accuracy: 0.4489\n",
      "Epoch 253/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2526 - accuracy: 0.4474 - val_loss: 1.2655 - val_accuracy: 0.4148\n",
      "Epoch 254/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2479 - accuracy: 0.4378 - val_loss: 1.2083 - val_accuracy: 0.4531\n",
      "Epoch 255/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2364 - accuracy: 0.4452 - val_loss: 1.2107 - val_accuracy: 0.4517\n",
      "Epoch 256/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2383 - accuracy: 0.4502 - val_loss: 1.2080 - val_accuracy: 0.4574\n",
      "Epoch 257/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2293 - accuracy: 0.4442 - val_loss: 1.2249 - val_accuracy: 0.4389\n",
      "Epoch 258/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2241 - accuracy: 0.4555 - val_loss: 1.2152 - val_accuracy: 0.4332\n",
      "Epoch 259/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2238 - accuracy: 0.4516 - val_loss: 1.2245 - val_accuracy: 0.4460\n",
      "Epoch 260/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2324 - accuracy: 0.4516 - val_loss: 1.2136 - val_accuracy: 0.4389\n",
      "Epoch 261/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2246 - accuracy: 0.4587 - val_loss: 1.2378 - val_accuracy: 0.4148\n",
      "Epoch 262/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2714 - accuracy: 0.4111 - val_loss: 1.2349 - val_accuracy: 0.3949\n",
      "Epoch 263/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2317 - accuracy: 0.4566 - val_loss: 1.2095 - val_accuracy: 0.4460\n",
      "Epoch 264/800\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.2186 - accuracy: 0.4577 - val_loss: 1.2310 - val_accuracy: 0.4332\n",
      "Epoch 265/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2206 - accuracy: 0.4634 - val_loss: 1.2532 - val_accuracy: 0.4176\n",
      "Epoch 266/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2200 - accuracy: 0.4587 - val_loss: 1.2094 - val_accuracy: 0.4418\n",
      "Epoch 267/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2322 - accuracy: 0.4435 - val_loss: 1.2575 - val_accuracy: 0.4318\n",
      "Epoch 268/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2297 - accuracy: 0.4499 - val_loss: 1.2091 - val_accuracy: 0.4489\n",
      "Epoch 269/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2494 - accuracy: 0.4467 - val_loss: 1.3109 - val_accuracy: 0.3835\n",
      "Epoch 270/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.3159 - accuracy: 0.3962 - val_loss: 1.2840 - val_accuracy: 0.3807\n",
      "Epoch 271/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3026 - accuracy: 0.4040 - val_loss: 1.2801 - val_accuracy: 0.3793\n",
      "Epoch 272/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2994 - accuracy: 0.4022 - val_loss: 1.2796 - val_accuracy: 0.3835\n",
      "Epoch 273/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2970 - accuracy: 0.4090 - val_loss: 1.2740 - val_accuracy: 0.4134\n",
      "Epoch 274/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2925 - accuracy: 0.4125 - val_loss: 1.2697 - val_accuracy: 0.4134\n",
      "Epoch 275/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2813 - accuracy: 0.4115 - val_loss: 1.2474 - val_accuracy: 0.4261\n",
      "Epoch 276/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2617 - accuracy: 0.4424 - val_loss: 1.2464 - val_accuracy: 0.4332\n",
      "Epoch 277/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2505 - accuracy: 0.4427 - val_loss: 1.2258 - val_accuracy: 0.4318\n",
      "Epoch 278/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2506 - accuracy: 0.4513 - val_loss: 1.2278 - val_accuracy: 0.4503\n",
      "Epoch 279/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2822 - accuracy: 0.4086 - val_loss: 1.2616 - val_accuracy: 0.3963\n",
      "Epoch 280/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2559 - accuracy: 0.4303 - val_loss: 1.2469 - val_accuracy: 0.4190\n",
      "Epoch 281/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2314 - accuracy: 0.4570 - val_loss: 1.2246 - val_accuracy: 0.4389\n",
      "Epoch 282/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2298 - accuracy: 0.4538 - val_loss: 1.2070 - val_accuracy: 0.4503\n",
      "Epoch 283/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2371 - accuracy: 0.4488 - val_loss: 1.2072 - val_accuracy: 0.4531\n",
      "Epoch 284/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2272 - accuracy: 0.4577 - val_loss: 1.2323 - val_accuracy: 0.4347\n",
      "Epoch 285/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2261 - accuracy: 0.4516 - val_loss: 1.2227 - val_accuracy: 0.4446\n",
      "Epoch 286/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2315 - accuracy: 0.4513 - val_loss: 1.2126 - val_accuracy: 0.4645\n",
      "Epoch 287/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2228 - accuracy: 0.4644 - val_loss: 1.2059 - val_accuracy: 0.4602\n",
      "Epoch 288/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2216 - accuracy: 0.4559 - val_loss: 1.2110 - val_accuracy: 0.4474\n",
      "Epoch 289/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2346 - accuracy: 0.4534 - val_loss: 1.2064 - val_accuracy: 0.4545\n",
      "Epoch 290/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3290 - accuracy: 0.3962 - val_loss: 1.2827 - val_accuracy: 0.3807\n",
      "Epoch 291/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.3017 - accuracy: 0.3908 - val_loss: 1.2817 - val_accuracy: 0.3821\n",
      "Epoch 292/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2959 - accuracy: 0.4008 - val_loss: 1.2760 - val_accuracy: 0.3991\n",
      "Epoch 293/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2937 - accuracy: 0.4040 - val_loss: 1.2698 - val_accuracy: 0.4318\n",
      "Epoch 294/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2896 - accuracy: 0.4083 - val_loss: 1.2681 - val_accuracy: 0.4148\n",
      "Epoch 295/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2866 - accuracy: 0.4061 - val_loss: 1.2630 - val_accuracy: 0.4276\n",
      "Epoch 296/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2873 - accuracy: 0.4008 - val_loss: 1.2603 - val_accuracy: 0.4190\n",
      "Epoch 297/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2590 - accuracy: 0.4353 - val_loss: 1.2348 - val_accuracy: 0.4389\n",
      "Epoch 298/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2390 - accuracy: 0.4584 - val_loss: 1.2435 - val_accuracy: 0.4261\n",
      "Epoch 299/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2686 - accuracy: 0.4342 - val_loss: 1.2862 - val_accuracy: 0.4006\n",
      "Epoch 300/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2603 - accuracy: 0.4385 - val_loss: 1.2205 - val_accuracy: 0.4616\n",
      "Epoch 301/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2392 - accuracy: 0.4438 - val_loss: 1.2107 - val_accuracy: 0.4588\n",
      "Epoch 302/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2374 - accuracy: 0.4477 - val_loss: 1.2707 - val_accuracy: 0.4290\n",
      "Epoch 303/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2343 - accuracy: 0.4523 - val_loss: 1.2937 - val_accuracy: 0.4190\n",
      "Epoch 304/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2597 - accuracy: 0.4296 - val_loss: 1.2808 - val_accuracy: 0.3878\n",
      "Epoch 305/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2445 - accuracy: 0.4463 - val_loss: 1.2206 - val_accuracy: 0.4460\n",
      "Epoch 306/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2327 - accuracy: 0.4506 - val_loss: 1.2086 - val_accuracy: 0.4489\n",
      "Epoch 307/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2207 - accuracy: 0.4484 - val_loss: 1.2142 - val_accuracy: 0.4503\n",
      "Epoch 308/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2449 - accuracy: 0.4506 - val_loss: 1.2081 - val_accuracy: 0.4517\n",
      "Epoch 309/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2341 - accuracy: 0.4491 - val_loss: 1.2091 - val_accuracy: 0.4375\n",
      "Epoch 310/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2205 - accuracy: 0.4577 - val_loss: 1.2519 - val_accuracy: 0.4361\n",
      "Epoch 311/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2348 - accuracy: 0.4495 - val_loss: 1.2142 - val_accuracy: 0.4432\n",
      "Epoch 312/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2449 - accuracy: 0.4374 - val_loss: 1.2256 - val_accuracy: 0.4190\n",
      "Epoch 313/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2158 - accuracy: 0.4559 - val_loss: 1.2092 - val_accuracy: 0.4318\n",
      "Epoch 314/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2254 - accuracy: 0.4619 - val_loss: 1.2122 - val_accuracy: 0.4389\n",
      "Epoch 315/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2174 - accuracy: 0.4545 - val_loss: 1.3046 - val_accuracy: 0.4162\n",
      "Epoch 316/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2282 - accuracy: 0.4445 - val_loss: 1.2037 - val_accuracy: 0.4503\n",
      "Epoch 317/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2334 - accuracy: 0.4516 - val_loss: 1.2328 - val_accuracy: 0.4247\n",
      "Epoch 318/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2303 - accuracy: 0.4570 - val_loss: 1.2168 - val_accuracy: 0.4545\n",
      "Epoch 319/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2142 - accuracy: 0.4566 - val_loss: 1.2095 - val_accuracy: 0.4531\n",
      "Epoch 320/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2212 - accuracy: 0.4577 - val_loss: 1.2101 - val_accuracy: 0.4474\n",
      "Epoch 321/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2974 - accuracy: 0.4054 - val_loss: 1.2779 - val_accuracy: 0.4034\n",
      "Epoch 322/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2950 - accuracy: 0.4040 - val_loss: 1.2721 - val_accuracy: 0.4148\n",
      "Epoch 323/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2919 - accuracy: 0.4079 - val_loss: 1.2772 - val_accuracy: 0.4091\n",
      "Epoch 324/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2904 - accuracy: 0.3994 - val_loss: 1.2716 - val_accuracy: 0.4162\n",
      "Epoch 325/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2862 - accuracy: 0.3997 - val_loss: 1.2782 - val_accuracy: 0.3821\n",
      "Epoch 326/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2848 - accuracy: 0.3986 - val_loss: 1.2569 - val_accuracy: 0.4020\n",
      "Epoch 327/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2600 - accuracy: 0.4335 - val_loss: 1.2379 - val_accuracy: 0.4588\n",
      "Epoch 328/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2624 - accuracy: 0.4360 - val_loss: 1.2335 - val_accuracy: 0.4418\n",
      "Epoch 329/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2387 - accuracy: 0.4527 - val_loss: 1.2227 - val_accuracy: 0.4403\n",
      "Epoch 330/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2467 - accuracy: 0.4445 - val_loss: 1.2647 - val_accuracy: 0.4062\n",
      "Epoch 331/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2413 - accuracy: 0.4477 - val_loss: 1.2142 - val_accuracy: 0.4403\n",
      "Epoch 332/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2412 - accuracy: 0.4591 - val_loss: 1.2508 - val_accuracy: 0.4062\n",
      "Epoch 333/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2316 - accuracy: 0.4591 - val_loss: 1.2448 - val_accuracy: 0.4290\n",
      "Epoch 334/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2285 - accuracy: 0.4648 - val_loss: 1.2082 - val_accuracy: 0.4531\n",
      "Epoch 335/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2573 - accuracy: 0.4481 - val_loss: 1.3964 - val_accuracy: 0.3509\n",
      "Epoch 336/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2615 - accuracy: 0.4271 - val_loss: 1.2175 - val_accuracy: 0.4531\n",
      "Epoch 337/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2206 - accuracy: 0.4623 - val_loss: 1.2072 - val_accuracy: 0.4347\n",
      "Epoch 338/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2233 - accuracy: 0.4595 - val_loss: 1.2084 - val_accuracy: 0.4545\n",
      "Epoch 339/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2274 - accuracy: 0.4499 - val_loss: 1.2091 - val_accuracy: 0.4517\n",
      "Epoch 340/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2213 - accuracy: 0.4559 - val_loss: 1.2205 - val_accuracy: 0.4517\n",
      "Epoch 341/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2390 - accuracy: 0.4403 - val_loss: 1.2977 - val_accuracy: 0.4077\n",
      "Epoch 342/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2801 - accuracy: 0.4161 - val_loss: 1.2242 - val_accuracy: 0.4304\n",
      "Epoch 343/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2232 - accuracy: 0.4555 - val_loss: 1.2189 - val_accuracy: 0.4517\n",
      "Epoch 344/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2205 - accuracy: 0.4545 - val_loss: 1.2548 - val_accuracy: 0.4304\n",
      "Epoch 345/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2382 - accuracy: 0.4413 - val_loss: 1.2242 - val_accuracy: 0.4318\n",
      "Epoch 346/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2154 - accuracy: 0.4612 - val_loss: 1.2047 - val_accuracy: 0.4545\n",
      "Epoch 347/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2186 - accuracy: 0.4520 - val_loss: 1.2048 - val_accuracy: 0.4489\n",
      "Epoch 348/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2517 - accuracy: 0.4335 - val_loss: 1.2109 - val_accuracy: 0.4432\n",
      "Epoch 349/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2752 - accuracy: 0.4250 - val_loss: 1.3013 - val_accuracy: 0.3864\n",
      "Epoch 350/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2766 - accuracy: 0.4235 - val_loss: 1.2801 - val_accuracy: 0.3949\n",
      "Epoch 351/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2956 - accuracy: 0.4090 - val_loss: 1.2731 - val_accuracy: 0.4233\n",
      "Epoch 352/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2899 - accuracy: 0.4083 - val_loss: 1.2788 - val_accuracy: 0.4048\n",
      "Epoch 353/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2892 - accuracy: 0.4033 - val_loss: 1.2643 - val_accuracy: 0.4304\n",
      "Epoch 354/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2828 - accuracy: 0.4047 - val_loss: 1.2751 - val_accuracy: 0.4190\n",
      "Epoch 355/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2651 - accuracy: 0.4275 - val_loss: 1.2397 - val_accuracy: 0.4134\n",
      "Epoch 356/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2360 - accuracy: 0.4545 - val_loss: 1.2199 - val_accuracy: 0.4517\n",
      "Epoch 357/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2401 - accuracy: 0.4495 - val_loss: 1.2178 - val_accuracy: 0.4432\n",
      "Epoch 358/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2333 - accuracy: 0.4534 - val_loss: 1.3009 - val_accuracy: 0.4091\n",
      "Epoch 359/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2268 - accuracy: 0.4527 - val_loss: 1.2192 - val_accuracy: 0.4418\n",
      "Epoch 360/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2501 - accuracy: 0.4381 - val_loss: 1.2280 - val_accuracy: 0.4261\n",
      "Epoch 361/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2472 - accuracy: 0.4463 - val_loss: 1.2228 - val_accuracy: 0.4474\n",
      "Epoch 362/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2319 - accuracy: 0.4538 - val_loss: 1.2204 - val_accuracy: 0.4403\n",
      "Epoch 363/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2239 - accuracy: 0.4527 - val_loss: 1.2158 - val_accuracy: 0.4503\n",
      "Epoch 364/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2378 - accuracy: 0.4580 - val_loss: 1.2310 - val_accuracy: 0.4276\n",
      "Epoch 365/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2436 - accuracy: 0.4353 - val_loss: 1.2301 - val_accuracy: 0.4219\n",
      "Epoch 366/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2271 - accuracy: 0.4531 - val_loss: 1.2130 - val_accuracy: 0.4474\n",
      "Epoch 367/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2114 - accuracy: 0.4698 - val_loss: 1.2019 - val_accuracy: 0.4545\n",
      "Epoch 368/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2267 - accuracy: 0.4463 - val_loss: 1.2208 - val_accuracy: 0.4276\n",
      "Epoch 369/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2243 - accuracy: 0.4577 - val_loss: 1.2311 - val_accuracy: 0.4318\n",
      "Epoch 370/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2292 - accuracy: 0.4548 - val_loss: 1.2140 - val_accuracy: 0.4304\n",
      "Epoch 371/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2232 - accuracy: 0.4580 - val_loss: 1.2634 - val_accuracy: 0.4162\n",
      "Epoch 372/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2257 - accuracy: 0.4452 - val_loss: 1.2098 - val_accuracy: 0.4318\n",
      "Epoch 373/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2137 - accuracy: 0.4584 - val_loss: 1.2254 - val_accuracy: 0.4332\n",
      "Epoch 374/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2230 - accuracy: 0.4580 - val_loss: 1.2407 - val_accuracy: 0.4148\n",
      "Epoch 375/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2596 - accuracy: 0.4470 - val_loss: 1.3014 - val_accuracy: 0.4062\n",
      "Epoch 376/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3011 - accuracy: 0.4068 - val_loss: 1.2727 - val_accuracy: 0.4105\n",
      "Epoch 377/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2905 - accuracy: 0.4125 - val_loss: 1.2730 - val_accuracy: 0.4119\n",
      "Epoch 378/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2871 - accuracy: 0.4111 - val_loss: 1.2658 - val_accuracy: 0.4077\n",
      "Epoch 379/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2836 - accuracy: 0.4122 - val_loss: 1.2612 - val_accuracy: 0.4105\n",
      "Epoch 380/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2814 - accuracy: 0.4022 - val_loss: 1.2676 - val_accuracy: 0.3878\n",
      "Epoch 381/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2768 - accuracy: 0.4097 - val_loss: 1.2482 - val_accuracy: 0.4205\n",
      "Epoch 382/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2545 - accuracy: 0.4435 - val_loss: 1.3355 - val_accuracy: 0.3991\n",
      "Epoch 383/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2555 - accuracy: 0.4392 - val_loss: 1.2083 - val_accuracy: 0.4517\n",
      "Epoch 384/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2625 - accuracy: 0.4303 - val_loss: 1.2559 - val_accuracy: 0.4034\n",
      "Epoch 385/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2732 - accuracy: 0.4129 - val_loss: 1.2665 - val_accuracy: 0.4034\n",
      "Epoch 386/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2712 - accuracy: 0.4232 - val_loss: 1.2424 - val_accuracy: 0.4290\n",
      "Epoch 387/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2456 - accuracy: 0.4371 - val_loss: 1.2092 - val_accuracy: 0.4517\n",
      "Epoch 388/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2284 - accuracy: 0.4630 - val_loss: 1.2166 - val_accuracy: 0.4474\n",
      "Epoch 389/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2847 - accuracy: 0.4179 - val_loss: 1.2722 - val_accuracy: 0.3622\n",
      "Epoch 390/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2697 - accuracy: 0.4267 - val_loss: 1.2469 - val_accuracy: 0.4077\n",
      "Epoch 391/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2427 - accuracy: 0.4491 - val_loss: 1.2192 - val_accuracy: 0.4588\n",
      "Epoch 392/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2284 - accuracy: 0.4598 - val_loss: 1.2270 - val_accuracy: 0.4418\n",
      "Epoch 393/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2499 - accuracy: 0.4339 - val_loss: 1.2062 - val_accuracy: 0.4460\n",
      "Epoch 394/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2507 - accuracy: 0.4292 - val_loss: 1.2056 - val_accuracy: 0.4574\n",
      "Epoch 395/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2600 - accuracy: 0.4285 - val_loss: 1.2393 - val_accuracy: 0.4233\n",
      "Epoch 396/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2397 - accuracy: 0.4488 - val_loss: 1.2061 - val_accuracy: 0.4517\n",
      "Epoch 397/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2404 - accuracy: 0.4499 - val_loss: 1.2386 - val_accuracy: 0.4190\n",
      "Epoch 398/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2353 - accuracy: 0.4506 - val_loss: 1.2029 - val_accuracy: 0.4418\n",
      "Epoch 399/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2133 - accuracy: 0.4623 - val_loss: 1.2063 - val_accuracy: 0.4560\n",
      "Epoch 400/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2240 - accuracy: 0.4591 - val_loss: 1.2105 - val_accuracy: 0.4517\n",
      "Epoch 401/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3108 - accuracy: 0.4011 - val_loss: 1.2819 - val_accuracy: 0.3807\n",
      "Epoch 402/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2916 - accuracy: 0.4065 - val_loss: 1.2695 - val_accuracy: 0.4190\n",
      "Epoch 403/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2884 - accuracy: 0.4068 - val_loss: 1.2651 - val_accuracy: 0.4119\n",
      "Epoch 404/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2849 - accuracy: 0.4072 - val_loss: 1.2612 - val_accuracy: 0.4176\n",
      "Epoch 405/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2807 - accuracy: 0.4018 - val_loss: 1.2618 - val_accuracy: 0.3906\n",
      "Epoch 406/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2657 - accuracy: 0.4246 - val_loss: 1.2229 - val_accuracy: 0.4460\n",
      "Epoch 407/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2420 - accuracy: 0.4555 - val_loss: 1.2978 - val_accuracy: 0.4105\n",
      "Epoch 408/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2683 - accuracy: 0.4271 - val_loss: 1.2242 - val_accuracy: 0.4318\n",
      "Epoch 409/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2225 - accuracy: 0.4516 - val_loss: 1.1994 - val_accuracy: 0.4616\n",
      "Epoch 410/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2521 - accuracy: 0.4321 - val_loss: 1.2636 - val_accuracy: 0.4020\n",
      "Epoch 411/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2327 - accuracy: 0.4516 - val_loss: 1.2049 - val_accuracy: 0.4588\n",
      "Epoch 412/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2236 - accuracy: 0.4598 - val_loss: 1.2324 - val_accuracy: 0.4261\n",
      "Epoch 413/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2288 - accuracy: 0.4513 - val_loss: 1.2075 - val_accuracy: 0.4574\n",
      "Epoch 414/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2219 - accuracy: 0.4619 - val_loss: 1.2113 - val_accuracy: 0.4361\n",
      "Epoch 415/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2522 - accuracy: 0.4374 - val_loss: 1.2218 - val_accuracy: 0.4474\n",
      "Epoch 416/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2225 - accuracy: 0.4566 - val_loss: 1.2089 - val_accuracy: 0.4460\n",
      "Epoch 417/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2344 - accuracy: 0.4513 - val_loss: 1.2231 - val_accuracy: 0.4332\n",
      "Epoch 418/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2162 - accuracy: 0.4570 - val_loss: 1.2157 - val_accuracy: 0.4503\n",
      "Epoch 419/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2295 - accuracy: 0.4548 - val_loss: 1.2108 - val_accuracy: 0.4517\n",
      "Epoch 420/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2142 - accuracy: 0.4591 - val_loss: 1.2038 - val_accuracy: 0.4418\n",
      "Epoch 421/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3054 - accuracy: 0.3944 - val_loss: 1.2729 - val_accuracy: 0.3949\n",
      "Epoch 422/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2857 - accuracy: 0.4018 - val_loss: 1.2629 - val_accuracy: 0.4034\n",
      "Epoch 423/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2815 - accuracy: 0.4058 - val_loss: 1.2625 - val_accuracy: 0.3864\n",
      "Epoch 424/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2784 - accuracy: 0.4036 - val_loss: 1.2668 - val_accuracy: 0.4077\n",
      "Epoch 425/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2761 - accuracy: 0.3947 - val_loss: 1.2536 - val_accuracy: 0.4091\n",
      "Epoch 426/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2618 - accuracy: 0.4438 - val_loss: 1.2299 - val_accuracy: 0.4531\n",
      "Epoch 427/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2477 - accuracy: 0.4573 - val_loss: 1.2091 - val_accuracy: 0.4588\n",
      "Epoch 428/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2415 - accuracy: 0.4509 - val_loss: 1.2516 - val_accuracy: 0.4290\n",
      "Epoch 429/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2566 - accuracy: 0.4410 - val_loss: 1.2105 - val_accuracy: 0.4545\n",
      "Epoch 430/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2640 - accuracy: 0.4317 - val_loss: 1.2769 - val_accuracy: 0.3807\n",
      "Epoch 431/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2413 - accuracy: 0.4513 - val_loss: 1.2237 - val_accuracy: 0.4375\n",
      "Epoch 432/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2267 - accuracy: 0.4591 - val_loss: 1.2063 - val_accuracy: 0.4503\n",
      "Epoch 433/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2673 - accuracy: 0.4303 - val_loss: 1.2667 - val_accuracy: 0.3693\n",
      "Epoch 434/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2573 - accuracy: 0.4378 - val_loss: 1.2219 - val_accuracy: 0.4375\n",
      "Epoch 435/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2593 - accuracy: 0.4363 - val_loss: 1.2610 - val_accuracy: 0.4162\n",
      "Epoch 436/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2577 - accuracy: 0.4378 - val_loss: 1.3362 - val_accuracy: 0.3892\n",
      "Epoch 437/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2747 - accuracy: 0.4267 - val_loss: 1.2255 - val_accuracy: 0.4332\n",
      "Epoch 438/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2274 - accuracy: 0.4602 - val_loss: 1.2048 - val_accuracy: 0.4602\n",
      "Epoch 439/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2244 - accuracy: 0.4552 - val_loss: 1.2195 - val_accuracy: 0.4361\n",
      "Epoch 440/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2314 - accuracy: 0.4527 - val_loss: 1.2102 - val_accuracy: 0.4446\n",
      "Epoch 441/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2361 - accuracy: 0.4502 - val_loss: 1.2378 - val_accuracy: 0.4148\n",
      "Epoch 442/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2289 - accuracy: 0.4534 - val_loss: 1.2171 - val_accuracy: 0.4503\n",
      "Epoch 443/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2433 - accuracy: 0.4523 - val_loss: 1.2065 - val_accuracy: 0.4389\n",
      "Epoch 444/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2206 - accuracy: 0.4641 - val_loss: 1.2060 - val_accuracy: 0.4517\n",
      "Epoch 445/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2203 - accuracy: 0.4673 - val_loss: 1.2599 - val_accuracy: 0.4176\n",
      "Epoch 446/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2318 - accuracy: 0.4573 - val_loss: 1.2231 - val_accuracy: 0.4389\n",
      "Epoch 447/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2220 - accuracy: 0.4623 - val_loss: 1.2712 - val_accuracy: 0.4233\n",
      "Epoch 448/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2116 - accuracy: 0.4612 - val_loss: 1.2299 - val_accuracy: 0.4332\n",
      "Epoch 449/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2139 - accuracy: 0.4651 - val_loss: 1.2129 - val_accuracy: 0.4446\n",
      "Epoch 450/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2093 - accuracy: 0.4612 - val_loss: 1.2417 - val_accuracy: 0.4361\n",
      "Epoch 451/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2326 - accuracy: 0.4520 - val_loss: 1.3379 - val_accuracy: 0.4034\n",
      "Epoch 452/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2815 - accuracy: 0.4203 - val_loss: 1.2136 - val_accuracy: 0.4361\n",
      "Epoch 453/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2158 - accuracy: 0.4683 - val_loss: 1.2443 - val_accuracy: 0.4290\n",
      "Epoch 454/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2175 - accuracy: 0.4580 - val_loss: 1.2196 - val_accuracy: 0.4474\n",
      "Epoch 455/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2371 - accuracy: 0.4491 - val_loss: 1.2137 - val_accuracy: 0.4418\n",
      "Epoch 456/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2343 - accuracy: 0.4541 - val_loss: 1.2870 - val_accuracy: 0.4205\n",
      "Epoch 457/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2348 - accuracy: 0.4516 - val_loss: 1.1976 - val_accuracy: 0.4560\n",
      "Epoch 458/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2172 - accuracy: 0.4577 - val_loss: 1.2654 - val_accuracy: 0.4261\n",
      "Epoch 459/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2753 - accuracy: 0.4221 - val_loss: 1.2668 - val_accuracy: 0.3807\n",
      "Epoch 460/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2278 - accuracy: 0.4531 - val_loss: 1.2221 - val_accuracy: 0.4432\n",
      "Epoch 461/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2312 - accuracy: 0.4563 - val_loss: 1.2062 - val_accuracy: 0.4588\n",
      "Epoch 462/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2181 - accuracy: 0.4619 - val_loss: 1.1969 - val_accuracy: 0.4588\n",
      "Epoch 463/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2306 - accuracy: 0.4573 - val_loss: 1.1984 - val_accuracy: 0.4574\n",
      "Epoch 464/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2231 - accuracy: 0.4559 - val_loss: 1.2048 - val_accuracy: 0.4460\n",
      "Epoch 465/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2262 - accuracy: 0.4481 - val_loss: 1.2234 - val_accuracy: 0.4361\n",
      "Epoch 466/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2264 - accuracy: 0.4555 - val_loss: 1.2048 - val_accuracy: 0.4474\n",
      "Epoch 467/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2858 - accuracy: 0.4168 - val_loss: 1.2456 - val_accuracy: 0.4077\n",
      "Epoch 468/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2264 - accuracy: 0.4523 - val_loss: 1.2335 - val_accuracy: 0.4389\n",
      "Epoch 469/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2228 - accuracy: 0.4523 - val_loss: 1.2044 - val_accuracy: 0.4403\n",
      "Epoch 470/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2155 - accuracy: 0.4552 - val_loss: 1.2071 - val_accuracy: 0.4318\n",
      "Epoch 471/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2207 - accuracy: 0.4541 - val_loss: 1.2041 - val_accuracy: 0.4545\n",
      "Epoch 472/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2132 - accuracy: 0.4552 - val_loss: 1.2023 - val_accuracy: 0.4432\n",
      "Epoch 473/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2157 - accuracy: 0.4545 - val_loss: 1.2116 - val_accuracy: 0.4489\n",
      "Epoch 474/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2843 - accuracy: 0.4022 - val_loss: 1.2814 - val_accuracy: 0.3821\n",
      "Epoch 475/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2954 - accuracy: 0.4058 - val_loss: 1.2753 - val_accuracy: 0.3793\n",
      "Epoch 476/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2917 - accuracy: 0.4026 - val_loss: 1.2709 - val_accuracy: 0.4219\n",
      "Epoch 477/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2851 - accuracy: 0.4068 - val_loss: 1.2652 - val_accuracy: 0.4148\n",
      "Epoch 478/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2833 - accuracy: 0.4040 - val_loss: 1.2699 - val_accuracy: 0.3821\n",
      "Epoch 479/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2734 - accuracy: 0.4189 - val_loss: 1.2458 - val_accuracy: 0.4276\n",
      "Epoch 480/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2558 - accuracy: 0.4349 - val_loss: 1.2164 - val_accuracy: 0.4403\n",
      "Epoch 481/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2342 - accuracy: 0.4531 - val_loss: 1.2118 - val_accuracy: 0.4503\n",
      "Epoch 482/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2667 - accuracy: 0.4285 - val_loss: 1.2805 - val_accuracy: 0.4105\n",
      "Epoch 483/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2320 - accuracy: 0.4506 - val_loss: 1.2196 - val_accuracy: 0.4304\n",
      "Epoch 484/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2299 - accuracy: 0.4552 - val_loss: 1.2704 - val_accuracy: 0.4034\n",
      "Epoch 485/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2370 - accuracy: 0.4538 - val_loss: 1.2889 - val_accuracy: 0.4006\n",
      "Epoch 486/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2188 - accuracy: 0.4637 - val_loss: 1.2046 - val_accuracy: 0.4517\n",
      "Epoch 487/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2984 - accuracy: 0.4083 - val_loss: 1.2717 - val_accuracy: 0.3864\n",
      "Epoch 488/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2874 - accuracy: 0.3937 - val_loss: 1.2641 - val_accuracy: 0.4134\n",
      "Epoch 489/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2838 - accuracy: 0.3979 - val_loss: 1.2596 - val_accuracy: 0.3991\n",
      "Epoch 490/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2763 - accuracy: 0.4011 - val_loss: 1.2505 - val_accuracy: 0.4077\n",
      "Epoch 491/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2540 - accuracy: 0.4452 - val_loss: 1.2217 - val_accuracy: 0.4261\n",
      "Epoch 492/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2397 - accuracy: 0.4534 - val_loss: 1.2135 - val_accuracy: 0.4418\n",
      "Epoch 493/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2358 - accuracy: 0.4627 - val_loss: 1.1978 - val_accuracy: 0.4787\n",
      "Epoch 494/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2222 - accuracy: 0.4577 - val_loss: 1.2156 - val_accuracy: 0.4474\n",
      "Epoch 495/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2240 - accuracy: 0.4509 - val_loss: 1.2020 - val_accuracy: 0.4588\n",
      "Epoch 496/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2314 - accuracy: 0.4527 - val_loss: 1.2119 - val_accuracy: 0.4531\n",
      "Epoch 497/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2199 - accuracy: 0.4570 - val_loss: 1.2235 - val_accuracy: 0.4276\n",
      "Epoch 498/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2301 - accuracy: 0.4580 - val_loss: 1.2644 - val_accuracy: 0.4091\n",
      "Epoch 499/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2237 - accuracy: 0.4552 - val_loss: 1.2251 - val_accuracy: 0.4432\n",
      "Epoch 500/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2326 - accuracy: 0.4467 - val_loss: 1.2038 - val_accuracy: 0.4418\n",
      "Epoch 501/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2188 - accuracy: 0.4623 - val_loss: 1.2003 - val_accuracy: 0.4645\n",
      "Epoch 502/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2864 - accuracy: 0.4253 - val_loss: 1.3089 - val_accuracy: 0.3778\n",
      "Epoch 503/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2900 - accuracy: 0.3997 - val_loss: 1.2671 - val_accuracy: 0.4162\n",
      "Epoch 504/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2740 - accuracy: 0.4072 - val_loss: 1.2373 - val_accuracy: 0.4219\n",
      "Epoch 505/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2526 - accuracy: 0.4424 - val_loss: 1.2202 - val_accuracy: 0.4489\n",
      "Epoch 506/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2357 - accuracy: 0.4662 - val_loss: 1.2074 - val_accuracy: 0.4517\n",
      "Epoch 507/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2694 - accuracy: 0.4267 - val_loss: 1.2238 - val_accuracy: 0.4219\n",
      "Epoch 508/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2307 - accuracy: 0.4520 - val_loss: 1.2051 - val_accuracy: 0.4545\n",
      "Epoch 509/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2362 - accuracy: 0.4531 - val_loss: 1.2272 - val_accuracy: 0.4517\n",
      "Epoch 510/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2263 - accuracy: 0.4548 - val_loss: 1.2062 - val_accuracy: 0.4560\n",
      "Epoch 511/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2134 - accuracy: 0.4577 - val_loss: 1.2058 - val_accuracy: 0.4503\n",
      "Epoch 512/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2230 - accuracy: 0.4520 - val_loss: 1.2057 - val_accuracy: 0.4432\n",
      "Epoch 513/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2116 - accuracy: 0.4641 - val_loss: 1.2005 - val_accuracy: 0.4688\n",
      "Epoch 514/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2121 - accuracy: 0.4651 - val_loss: 1.2306 - val_accuracy: 0.4290\n",
      "Epoch 515/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2373 - accuracy: 0.4566 - val_loss: 1.2043 - val_accuracy: 0.4545\n",
      "Epoch 516/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2129 - accuracy: 0.4580 - val_loss: 1.2055 - val_accuracy: 0.4489\n",
      "Epoch 517/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2175 - accuracy: 0.4630 - val_loss: 1.2046 - val_accuracy: 0.4489\n",
      "Epoch 518/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2140 - accuracy: 0.4609 - val_loss: 1.1970 - val_accuracy: 0.4588\n",
      "Epoch 519/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2294 - accuracy: 0.4527 - val_loss: 1.2309 - val_accuracy: 0.4048\n",
      "Epoch 520/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2238 - accuracy: 0.4467 - val_loss: 1.1964 - val_accuracy: 0.4716\n",
      "Epoch 521/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2184 - accuracy: 0.4627 - val_loss: 1.2263 - val_accuracy: 0.4432\n",
      "Epoch 522/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2220 - accuracy: 0.4516 - val_loss: 1.2109 - val_accuracy: 0.4574\n",
      "Epoch 523/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2030 - accuracy: 0.4612 - val_loss: 1.2098 - val_accuracy: 0.4574\n",
      "Epoch 524/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2076 - accuracy: 0.4570 - val_loss: 1.1990 - val_accuracy: 0.4702\n",
      "Epoch 525/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2186 - accuracy: 0.4612 - val_loss: 1.2012 - val_accuracy: 0.4474\n",
      "Epoch 526/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2318 - accuracy: 0.4559 - val_loss: 1.2117 - val_accuracy: 0.4560\n",
      "Epoch 527/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2283 - accuracy: 0.4481 - val_loss: 1.2075 - val_accuracy: 0.4347\n",
      "Epoch 528/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2077 - accuracy: 0.4587 - val_loss: 1.2065 - val_accuracy: 0.4517\n",
      "Epoch 529/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2179 - accuracy: 0.4531 - val_loss: 1.2220 - val_accuracy: 0.4517\n",
      "Epoch 530/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2093 - accuracy: 0.4605 - val_loss: 1.2015 - val_accuracy: 0.4503\n",
      "Epoch 531/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2081 - accuracy: 0.4538 - val_loss: 1.2035 - val_accuracy: 0.4460\n",
      "Epoch 532/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2472 - accuracy: 0.4577 - val_loss: 1.2846 - val_accuracy: 0.3849\n",
      "Epoch 533/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.3012 - accuracy: 0.3986 - val_loss: 1.2748 - val_accuracy: 0.4062\n",
      "Epoch 534/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2941 - accuracy: 0.4072 - val_loss: 1.2709 - val_accuracy: 0.4148\n",
      "Epoch 535/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2878 - accuracy: 0.4083 - val_loss: 1.2710 - val_accuracy: 0.4162\n",
      "Epoch 536/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2849 - accuracy: 0.4118 - val_loss: 1.2629 - val_accuracy: 0.4233\n",
      "Epoch 537/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2822 - accuracy: 0.3954 - val_loss: 1.2604 - val_accuracy: 0.4006\n",
      "Epoch 538/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2775 - accuracy: 0.4022 - val_loss: 1.2724 - val_accuracy: 0.3651\n",
      "Epoch 539/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2802 - accuracy: 0.4029 - val_loss: 1.2568 - val_accuracy: 0.3807\n",
      "Epoch 540/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2766 - accuracy: 0.4022 - val_loss: 1.2551 - val_accuracy: 0.3835\n",
      "Epoch 541/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2751 - accuracy: 0.4097 - val_loss: 1.2597 - val_accuracy: 0.4062\n",
      "Epoch 542/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2464 - accuracy: 0.4513 - val_loss: 1.2059 - val_accuracy: 0.4545\n",
      "Epoch 543/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2292 - accuracy: 0.4623 - val_loss: 1.2234 - val_accuracy: 0.4361\n",
      "Epoch 544/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2532 - accuracy: 0.4435 - val_loss: 1.2082 - val_accuracy: 0.4616\n",
      "Epoch 545/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2292 - accuracy: 0.4580 - val_loss: 1.2075 - val_accuracy: 0.4474\n",
      "Epoch 546/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2340 - accuracy: 0.4580 - val_loss: 1.2001 - val_accuracy: 0.4616\n",
      "Epoch 547/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2241 - accuracy: 0.4673 - val_loss: 1.2061 - val_accuracy: 0.4574\n",
      "Epoch 548/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2240 - accuracy: 0.4495 - val_loss: 1.2627 - val_accuracy: 0.4304\n",
      "Epoch 549/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2441 - accuracy: 0.4509 - val_loss: 1.2535 - val_accuracy: 0.4304\n",
      "Epoch 550/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2345 - accuracy: 0.4563 - val_loss: 1.2110 - val_accuracy: 0.4489\n",
      "Epoch 551/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2775 - accuracy: 0.4001 - val_loss: 1.2658 - val_accuracy: 0.3949\n",
      "Epoch 552/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2674 - accuracy: 0.4211 - val_loss: 1.2287 - val_accuracy: 0.4389\n",
      "Epoch 553/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2440 - accuracy: 0.4548 - val_loss: 1.2109 - val_accuracy: 0.4446\n",
      "Epoch 554/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2370 - accuracy: 0.4555 - val_loss: 1.2087 - val_accuracy: 0.4418\n",
      "Epoch 555/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2336 - accuracy: 0.4555 - val_loss: 1.2064 - val_accuracy: 0.4474\n",
      "Epoch 556/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2174 - accuracy: 0.4623 - val_loss: 1.1985 - val_accuracy: 0.4531\n",
      "Epoch 557/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2142 - accuracy: 0.4676 - val_loss: 1.1944 - val_accuracy: 0.4616\n",
      "Epoch 558/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2350 - accuracy: 0.4438 - val_loss: 1.2318 - val_accuracy: 0.4332\n",
      "Epoch 559/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2234 - accuracy: 0.4591 - val_loss: 1.2090 - val_accuracy: 0.4503\n",
      "Epoch 560/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2160 - accuracy: 0.4520 - val_loss: 1.2846 - val_accuracy: 0.4176\n",
      "Epoch 561/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2438 - accuracy: 0.4435 - val_loss: 1.1952 - val_accuracy: 0.4716\n",
      "Epoch 562/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2192 - accuracy: 0.4566 - val_loss: 1.2061 - val_accuracy: 0.4489\n",
      "Epoch 563/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2122 - accuracy: 0.4605 - val_loss: 1.1940 - val_accuracy: 0.4688\n",
      "Epoch 564/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2162 - accuracy: 0.4570 - val_loss: 1.2118 - val_accuracy: 0.4318\n",
      "Epoch 565/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2148 - accuracy: 0.4580 - val_loss: 1.2080 - val_accuracy: 0.4517\n",
      "Epoch 566/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2112 - accuracy: 0.4573 - val_loss: 1.2026 - val_accuracy: 0.4418\n",
      "Epoch 567/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2044 - accuracy: 0.4616 - val_loss: 1.1953 - val_accuracy: 0.4545\n",
      "Epoch 568/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2208 - accuracy: 0.4527 - val_loss: 1.2035 - val_accuracy: 0.4474\n",
      "Epoch 569/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2201 - accuracy: 0.4687 - val_loss: 1.2083 - val_accuracy: 0.4489\n",
      "Epoch 570/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2150 - accuracy: 0.4634 - val_loss: 1.2002 - val_accuracy: 0.4602\n",
      "Epoch 571/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2184 - accuracy: 0.4587 - val_loss: 1.1918 - val_accuracy: 0.4645\n",
      "Epoch 572/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2350 - accuracy: 0.4491 - val_loss: 1.2312 - val_accuracy: 0.4318\n",
      "Epoch 573/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2114 - accuracy: 0.4666 - val_loss: 1.1934 - val_accuracy: 0.4602\n",
      "Epoch 574/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2712 - accuracy: 0.4182 - val_loss: 1.2723 - val_accuracy: 0.4276\n",
      "Epoch 575/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2887 - accuracy: 0.4132 - val_loss: 1.2666 - val_accuracy: 0.4190\n",
      "Epoch 576/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2847 - accuracy: 0.4093 - val_loss: 1.2631 - val_accuracy: 0.4134\n",
      "Epoch 577/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2813 - accuracy: 0.4050 - val_loss: 1.2581 - val_accuracy: 0.4233\n",
      "Epoch 578/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2781 - accuracy: 0.3962 - val_loss: 1.2592 - val_accuracy: 0.3878\n",
      "Epoch 579/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2763 - accuracy: 0.4065 - val_loss: 1.2643 - val_accuracy: 0.3878\n",
      "Epoch 580/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2621 - accuracy: 0.4321 - val_loss: 1.2362 - val_accuracy: 0.4432\n",
      "Epoch 581/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2398 - accuracy: 0.4456 - val_loss: 1.3392 - val_accuracy: 0.4077\n",
      "Epoch 582/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2748 - accuracy: 0.4264 - val_loss: 1.2108 - val_accuracy: 0.4545\n",
      "Epoch 583/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2337 - accuracy: 0.4509 - val_loss: 1.2031 - val_accuracy: 0.4602\n",
      "Epoch 584/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2440 - accuracy: 0.4438 - val_loss: 1.1974 - val_accuracy: 0.4631\n",
      "Epoch 585/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2166 - accuracy: 0.4662 - val_loss: 1.2312 - val_accuracy: 0.4304\n",
      "Epoch 586/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2186 - accuracy: 0.4612 - val_loss: 1.1931 - val_accuracy: 0.4659\n",
      "Epoch 587/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2499 - accuracy: 0.4406 - val_loss: 1.1937 - val_accuracy: 0.4560\n",
      "Epoch 588/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2475 - accuracy: 0.4449 - val_loss: 1.2873 - val_accuracy: 0.4034\n",
      "Epoch 589/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2279 - accuracy: 0.4573 - val_loss: 1.1952 - val_accuracy: 0.4673\n",
      "Epoch 590/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2219 - accuracy: 0.4605 - val_loss: 1.2255 - val_accuracy: 0.4375\n",
      "Epoch 591/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2114 - accuracy: 0.4566 - val_loss: 1.2316 - val_accuracy: 0.4432\n",
      "Epoch 592/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2062 - accuracy: 0.4627 - val_loss: 1.1882 - val_accuracy: 0.4801\n",
      "Epoch 593/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2106 - accuracy: 0.4602 - val_loss: 1.2764 - val_accuracy: 0.4119\n",
      "Epoch 594/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2174 - accuracy: 0.4627 - val_loss: 1.2183 - val_accuracy: 0.4418\n",
      "Epoch 595/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2353 - accuracy: 0.4484 - val_loss: 1.2044 - val_accuracy: 0.4517\n",
      "Epoch 596/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2252 - accuracy: 0.4566 - val_loss: 1.2284 - val_accuracy: 0.4375\n",
      "Epoch 597/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2171 - accuracy: 0.4552 - val_loss: 1.1971 - val_accuracy: 0.4489\n",
      "Epoch 598/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2152 - accuracy: 0.4609 - val_loss: 1.2363 - val_accuracy: 0.4233\n",
      "Epoch 599/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2047 - accuracy: 0.4630 - val_loss: 1.1902 - val_accuracy: 0.4503\n",
      "Epoch 600/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2600 - accuracy: 0.4267 - val_loss: 1.2681 - val_accuracy: 0.4134\n",
      "Epoch 601/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2858 - accuracy: 0.4065 - val_loss: 1.2585 - val_accuracy: 0.4006\n",
      "Epoch 602/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2807 - accuracy: 0.4079 - val_loss: 1.2552 - val_accuracy: 0.4119\n",
      "Epoch 603/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2586 - accuracy: 0.4289 - val_loss: 1.2222 - val_accuracy: 0.4304\n",
      "Epoch 604/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2261 - accuracy: 0.4605 - val_loss: 1.2298 - val_accuracy: 0.4318\n",
      "Epoch 605/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2175 - accuracy: 0.4659 - val_loss: 1.1975 - val_accuracy: 0.4588\n",
      "Epoch 606/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2153 - accuracy: 0.4669 - val_loss: 1.3113 - val_accuracy: 0.4119\n",
      "Epoch 607/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2082 - accuracy: 0.4651 - val_loss: 1.1898 - val_accuracy: 0.4616\n",
      "Epoch 608/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2923 - accuracy: 0.4036 - val_loss: 1.2619 - val_accuracy: 0.4205\n",
      "Epoch 609/800\n",
      "88/88 [==============================] - 1s 9ms/step - loss: 1.2813 - accuracy: 0.4111 - val_loss: 1.2706 - val_accuracy: 0.3906\n",
      "Epoch 610/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2802 - accuracy: 0.4050 - val_loss: 1.2552 - val_accuracy: 0.4205\n",
      "Epoch 611/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2756 - accuracy: 0.4083 - val_loss: 1.2505 - val_accuracy: 0.4062\n",
      "Epoch 612/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2435 - accuracy: 0.4427 - val_loss: 1.2090 - val_accuracy: 0.4460\n",
      "Epoch 613/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2356 - accuracy: 0.4534 - val_loss: 1.2129 - val_accuracy: 0.4517\n",
      "Epoch 614/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2170 - accuracy: 0.4648 - val_loss: 1.2765 - val_accuracy: 0.4219\n",
      "Epoch 615/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2988 - accuracy: 0.3947 - val_loss: 1.2670 - val_accuracy: 0.4176\n",
      "Epoch 616/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2830 - accuracy: 0.4104 - val_loss: 1.2603 - val_accuracy: 0.4034\n",
      "Epoch 617/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2770 - accuracy: 0.4065 - val_loss: 1.2502 - val_accuracy: 0.4105\n",
      "Epoch 618/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2613 - accuracy: 0.4278 - val_loss: 1.2200 - val_accuracy: 0.4418\n",
      "Epoch 619/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2354 - accuracy: 0.4598 - val_loss: 1.2039 - val_accuracy: 0.4631\n",
      "Epoch 620/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2249 - accuracy: 0.4619 - val_loss: 1.2070 - val_accuracy: 0.4489\n",
      "Epoch 621/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.4484 - val_loss: 1.1977 - val_accuracy: 0.4574\n",
      "Epoch 622/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2346 - accuracy: 0.4531 - val_loss: 1.2090 - val_accuracy: 0.4588\n",
      "Epoch 623/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2185 - accuracy: 0.4619 - val_loss: 1.1965 - val_accuracy: 0.4616\n",
      "Epoch 624/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2343 - accuracy: 0.4516 - val_loss: 1.2109 - val_accuracy: 0.4418\n",
      "Epoch 625/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2178 - accuracy: 0.4595 - val_loss: 1.1981 - val_accuracy: 0.4645\n",
      "Epoch 626/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2137 - accuracy: 0.4619 - val_loss: 1.2079 - val_accuracy: 0.4503\n",
      "Epoch 627/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2102 - accuracy: 0.4619 - val_loss: 1.1928 - val_accuracy: 0.4531\n",
      "Epoch 628/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2190 - accuracy: 0.4527 - val_loss: 1.1985 - val_accuracy: 0.4560\n",
      "Epoch 629/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2123 - accuracy: 0.4630 - val_loss: 1.2854 - val_accuracy: 0.4034\n",
      "Epoch 630/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2120 - accuracy: 0.4612 - val_loss: 1.1887 - val_accuracy: 0.4588\n",
      "Epoch 631/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1977 - accuracy: 0.4712 - val_loss: 1.1882 - val_accuracy: 0.4688\n",
      "Epoch 632/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2010 - accuracy: 0.4595 - val_loss: 1.2093 - val_accuracy: 0.4474\n",
      "Epoch 633/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2370 - accuracy: 0.4484 - val_loss: 1.2288 - val_accuracy: 0.4261\n",
      "Epoch 634/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2165 - accuracy: 0.4605 - val_loss: 1.2140 - val_accuracy: 0.4503\n",
      "Epoch 635/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2165 - accuracy: 0.4683 - val_loss: 1.2008 - val_accuracy: 0.4531\n",
      "Epoch 636/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2530 - accuracy: 0.4438 - val_loss: 1.1924 - val_accuracy: 0.4588\n",
      "Epoch 637/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2206 - accuracy: 0.4509 - val_loss: 1.1950 - val_accuracy: 0.4517\n",
      "Epoch 638/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2096 - accuracy: 0.4669 - val_loss: 1.2097 - val_accuracy: 0.4432\n",
      "Epoch 639/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2159 - accuracy: 0.4591 - val_loss: 1.1959 - val_accuracy: 0.4602\n",
      "Epoch 640/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1983 - accuracy: 0.4683 - val_loss: 1.1827 - val_accuracy: 0.4801\n",
      "Epoch 641/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.1952 - accuracy: 0.4726 - val_loss: 1.1847 - val_accuracy: 0.4787\n",
      "Epoch 642/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2322 - accuracy: 0.4499 - val_loss: 1.2003 - val_accuracy: 0.4460\n",
      "Epoch 643/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2244 - accuracy: 0.4541 - val_loss: 1.1954 - val_accuracy: 0.4602\n",
      "Epoch 644/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2486 - accuracy: 0.4420 - val_loss: 1.2709 - val_accuracy: 0.4205\n",
      "Epoch 645/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2920 - accuracy: 0.4026 - val_loss: 1.2606 - val_accuracy: 0.4119\n",
      "Epoch 646/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2805 - accuracy: 0.4143 - val_loss: 1.2577 - val_accuracy: 0.4148\n",
      "Epoch 647/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2777 - accuracy: 0.4100 - val_loss: 1.2539 - val_accuracy: 0.4162\n",
      "Epoch 648/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2752 - accuracy: 0.4122 - val_loss: 1.2537 - val_accuracy: 0.4105\n",
      "Epoch 649/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2727 - accuracy: 0.4040 - val_loss: 1.2544 - val_accuracy: 0.4119\n",
      "Epoch 650/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2602 - accuracy: 0.4235 - val_loss: 1.2339 - val_accuracy: 0.4375\n",
      "Epoch 651/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2439 - accuracy: 0.4349 - val_loss: 1.2169 - val_accuracy: 0.4616\n",
      "Epoch 652/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2341 - accuracy: 0.4527 - val_loss: 1.2056 - val_accuracy: 0.4574\n",
      "Epoch 653/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2207 - accuracy: 0.4605 - val_loss: 1.2354 - val_accuracy: 0.4276\n",
      "Epoch 654/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2139 - accuracy: 0.4683 - val_loss: 1.1975 - val_accuracy: 0.4574\n",
      "Epoch 655/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2053 - accuracy: 0.4673 - val_loss: 1.1988 - val_accuracy: 0.4560\n",
      "Epoch 656/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2232 - accuracy: 0.4577 - val_loss: 1.1917 - val_accuracy: 0.4688\n",
      "Epoch 657/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2278 - accuracy: 0.4559 - val_loss: 1.2261 - val_accuracy: 0.4304\n",
      "Epoch 658/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2288 - accuracy: 0.4506 - val_loss: 1.1986 - val_accuracy: 0.4616\n",
      "Epoch 659/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2072 - accuracy: 0.4698 - val_loss: 1.1877 - val_accuracy: 0.4773\n",
      "Epoch 660/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2220 - accuracy: 0.4573 - val_loss: 1.1966 - val_accuracy: 0.4602\n",
      "Epoch 661/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2060 - accuracy: 0.4573 - val_loss: 1.2184 - val_accuracy: 0.4446\n",
      "Epoch 662/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2133 - accuracy: 0.4541 - val_loss: 1.2013 - val_accuracy: 0.4460\n",
      "Epoch 663/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.1998 - accuracy: 0.4641 - val_loss: 1.1879 - val_accuracy: 0.4645\n",
      "Epoch 664/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2131 - accuracy: 0.4648 - val_loss: 1.1938 - val_accuracy: 0.4787\n",
      "Epoch 665/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2359 - accuracy: 0.4424 - val_loss: 1.2579 - val_accuracy: 0.4219\n",
      "Epoch 666/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2259 - accuracy: 0.4516 - val_loss: 1.2182 - val_accuracy: 0.4517\n",
      "Epoch 667/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2042 - accuracy: 0.4669 - val_loss: 1.1828 - val_accuracy: 0.4702\n",
      "Epoch 668/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2379 - accuracy: 0.4452 - val_loss: 1.2067 - val_accuracy: 0.4389\n",
      "Epoch 669/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2670 - accuracy: 0.4182 - val_loss: 1.2645 - val_accuracy: 0.4176\n",
      "Epoch 670/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2816 - accuracy: 0.4079 - val_loss: 1.2624 - val_accuracy: 0.4048\n",
      "Epoch 671/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2753 - accuracy: 0.4033 - val_loss: 1.2531 - val_accuracy: 0.4219\n",
      "Epoch 672/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2742 - accuracy: 0.4054 - val_loss: 1.2540 - val_accuracy: 0.4091\n",
      "Epoch 673/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2654 - accuracy: 0.4207 - val_loss: 1.2325 - val_accuracy: 0.4048\n",
      "Epoch 674/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2438 - accuracy: 0.4413 - val_loss: 1.2192 - val_accuracy: 0.4489\n",
      "Epoch 675/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2463 - accuracy: 0.4559 - val_loss: 1.2378 - val_accuracy: 0.4304\n",
      "Epoch 676/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2227 - accuracy: 0.4669 - val_loss: 1.1964 - val_accuracy: 0.4631\n",
      "Epoch 677/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2357 - accuracy: 0.4531 - val_loss: 1.1859 - val_accuracy: 0.4844\n",
      "Epoch 678/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2240 - accuracy: 0.4577 - val_loss: 1.2324 - val_accuracy: 0.4304\n",
      "Epoch 679/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2179 - accuracy: 0.4641 - val_loss: 1.2236 - val_accuracy: 0.4347\n",
      "Epoch 680/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2197 - accuracy: 0.4644 - val_loss: 1.1908 - val_accuracy: 0.4830\n",
      "Epoch 681/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2096 - accuracy: 0.4637 - val_loss: 1.4588 - val_accuracy: 0.3452\n",
      "Epoch 682/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2691 - accuracy: 0.4445 - val_loss: 1.1892 - val_accuracy: 0.4631\n",
      "Epoch 683/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2037 - accuracy: 0.4683 - val_loss: 1.1939 - val_accuracy: 0.4545\n",
      "Epoch 684/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2263 - accuracy: 0.4463 - val_loss: 1.2270 - val_accuracy: 0.4375\n",
      "Epoch 685/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2168 - accuracy: 0.4566 - val_loss: 1.2296 - val_accuracy: 0.4347\n",
      "Epoch 686/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2039 - accuracy: 0.4708 - val_loss: 1.1869 - val_accuracy: 0.4645\n",
      "Epoch 687/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2071 - accuracy: 0.4687 - val_loss: 1.1922 - val_accuracy: 0.4588\n",
      "Epoch 688/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2120 - accuracy: 0.4662 - val_loss: 1.2235 - val_accuracy: 0.4361\n",
      "Epoch 689/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2019 - accuracy: 0.4669 - val_loss: 1.2003 - val_accuracy: 0.4545\n",
      "Epoch 690/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2200 - accuracy: 0.4552 - val_loss: 1.1952 - val_accuracy: 0.4602\n",
      "Epoch 691/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2165 - accuracy: 0.4612 - val_loss: 1.1879 - val_accuracy: 0.4744\n",
      "Epoch 692/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2104 - accuracy: 0.4609 - val_loss: 1.1894 - val_accuracy: 0.4744\n",
      "Epoch 693/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2108 - accuracy: 0.4680 - val_loss: 1.1921 - val_accuracy: 0.4631\n",
      "Epoch 694/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2023 - accuracy: 0.4609 - val_loss: 1.1894 - val_accuracy: 0.4688\n",
      "Epoch 695/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2130 - accuracy: 0.4598 - val_loss: 1.2138 - val_accuracy: 0.4474\n",
      "Epoch 696/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2147 - accuracy: 0.4637 - val_loss: 1.1868 - val_accuracy: 0.4631\n",
      "Epoch 697/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2072 - accuracy: 0.4673 - val_loss: 1.2669 - val_accuracy: 0.4347\n",
      "Epoch 698/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2331 - accuracy: 0.4612 - val_loss: 1.1977 - val_accuracy: 0.4616\n",
      "Epoch 699/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2183 - accuracy: 0.4587 - val_loss: 1.1888 - val_accuracy: 0.4659\n",
      "Epoch 700/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2020 - accuracy: 0.4616 - val_loss: 1.2125 - val_accuracy: 0.4574\n",
      "Epoch 701/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.1995 - accuracy: 0.4655 - val_loss: 1.1968 - val_accuracy: 0.4489\n",
      "Epoch 702/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.1965 - accuracy: 0.4694 - val_loss: 1.1857 - val_accuracy: 0.4730\n",
      "Epoch 703/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2023 - accuracy: 0.4570 - val_loss: 1.1901 - val_accuracy: 0.4588\n",
      "Epoch 704/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2044 - accuracy: 0.4637 - val_loss: 1.1898 - val_accuracy: 0.4489\n",
      "Epoch 705/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1963 - accuracy: 0.4712 - val_loss: 1.1938 - val_accuracy: 0.4673\n",
      "Epoch 706/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2032 - accuracy: 0.4623 - val_loss: 1.1880 - val_accuracy: 0.4616\n",
      "Epoch 707/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2023 - accuracy: 0.4641 - val_loss: 1.1901 - val_accuracy: 0.4744\n",
      "Epoch 708/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2116 - accuracy: 0.4641 - val_loss: 1.2320 - val_accuracy: 0.4261\n",
      "Epoch 709/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2027 - accuracy: 0.4683 - val_loss: 1.1887 - val_accuracy: 0.4645\n",
      "Epoch 710/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2064 - accuracy: 0.4648 - val_loss: 1.1893 - val_accuracy: 0.4702\n",
      "Epoch 711/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2596 - accuracy: 0.4388 - val_loss: 1.2792 - val_accuracy: 0.3849\n",
      "Epoch 712/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2874 - accuracy: 0.4043 - val_loss: 1.2669 - val_accuracy: 0.4162\n",
      "Epoch 713/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2828 - accuracy: 0.4139 - val_loss: 1.2611 - val_accuracy: 0.4119\n",
      "Epoch 714/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2816 - accuracy: 0.4218 - val_loss: 1.2600 - val_accuracy: 0.4176\n",
      "Epoch 715/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2782 - accuracy: 0.4115 - val_loss: 1.2752 - val_accuracy: 0.3665\n",
      "Epoch 716/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2687 - accuracy: 0.4175 - val_loss: 1.2300 - val_accuracy: 0.4148\n",
      "Epoch 717/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2380 - accuracy: 0.4371 - val_loss: 1.2019 - val_accuracy: 0.4588\n",
      "Epoch 718/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2423 - accuracy: 0.4527 - val_loss: 1.2240 - val_accuracy: 0.4432\n",
      "Epoch 719/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2181 - accuracy: 0.4648 - val_loss: 1.2312 - val_accuracy: 0.4418\n",
      "Epoch 720/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2014 - accuracy: 0.4701 - val_loss: 1.1849 - val_accuracy: 0.4773\n",
      "Epoch 721/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.1979 - accuracy: 0.4723 - val_loss: 1.1816 - val_accuracy: 0.4759\n",
      "Epoch 722/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2068 - accuracy: 0.4623 - val_loss: 1.1912 - val_accuracy: 0.4645\n",
      "Epoch 723/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2188 - accuracy: 0.4602 - val_loss: 1.2207 - val_accuracy: 0.4332\n",
      "Epoch 724/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2341 - accuracy: 0.4442 - val_loss: 1.2138 - val_accuracy: 0.4148\n",
      "Epoch 725/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2173 - accuracy: 0.4612 - val_loss: 1.2046 - val_accuracy: 0.4531\n",
      "Epoch 726/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2183 - accuracy: 0.4520 - val_loss: 1.1862 - val_accuracy: 0.4744\n",
      "Epoch 727/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2479 - accuracy: 0.4420 - val_loss: 1.2722 - val_accuracy: 0.4105\n",
      "Epoch 728/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2253 - accuracy: 0.4559 - val_loss: 1.1854 - val_accuracy: 0.4744\n",
      "Epoch 729/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2047 - accuracy: 0.4641 - val_loss: 1.1862 - val_accuracy: 0.4673\n",
      "Epoch 730/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2089 - accuracy: 0.4655 - val_loss: 1.1840 - val_accuracy: 0.4574\n",
      "Epoch 731/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2049 - accuracy: 0.4705 - val_loss: 1.2348 - val_accuracy: 0.4162\n",
      "Epoch 732/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2062 - accuracy: 0.4662 - val_loss: 1.1837 - val_accuracy: 0.4759\n",
      "Epoch 733/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2080 - accuracy: 0.4666 - val_loss: 1.1840 - val_accuracy: 0.4801\n",
      "Epoch 734/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2074 - accuracy: 0.4609 - val_loss: 1.1851 - val_accuracy: 0.4659\n",
      "Epoch 735/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2136 - accuracy: 0.4573 - val_loss: 1.2768 - val_accuracy: 0.4119\n",
      "Epoch 736/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2088 - accuracy: 0.4666 - val_loss: 1.2063 - val_accuracy: 0.4517\n",
      "Epoch 737/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2051 - accuracy: 0.4616 - val_loss: 1.1949 - val_accuracy: 0.4631\n",
      "Epoch 738/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2020 - accuracy: 0.4673 - val_loss: 1.2408 - val_accuracy: 0.4347\n",
      "Epoch 739/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2198 - accuracy: 0.4563 - val_loss: 1.1887 - val_accuracy: 0.4602\n",
      "Epoch 740/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.1957 - accuracy: 0.4701 - val_loss: 1.1985 - val_accuracy: 0.4588\n",
      "Epoch 741/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.2235 - accuracy: 0.4499 - val_loss: 1.2403 - val_accuracy: 0.4361\n",
      "Epoch 742/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2130 - accuracy: 0.4559 - val_loss: 1.1912 - val_accuracy: 0.4531\n",
      "Epoch 743/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2189 - accuracy: 0.4470 - val_loss: 1.2003 - val_accuracy: 0.4517\n",
      "Epoch 744/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2088 - accuracy: 0.4627 - val_loss: 1.1855 - val_accuracy: 0.4716\n",
      "Epoch 745/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1978 - accuracy: 0.4716 - val_loss: 1.2009 - val_accuracy: 0.4531\n",
      "Epoch 746/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.1975 - accuracy: 0.4691 - val_loss: 1.1901 - val_accuracy: 0.4688\n",
      "Epoch 747/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2205 - accuracy: 0.4630 - val_loss: 1.1914 - val_accuracy: 0.4702\n",
      "Epoch 748/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1962 - accuracy: 0.4716 - val_loss: 1.1825 - val_accuracy: 0.4744\n",
      "Epoch 749/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.1962 - accuracy: 0.4648 - val_loss: 1.2273 - val_accuracy: 0.4460\n",
      "Epoch 750/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2032 - accuracy: 0.4591 - val_loss: 1.1824 - val_accuracy: 0.4801\n",
      "Epoch 751/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2093 - accuracy: 0.4673 - val_loss: 1.1996 - val_accuracy: 0.4631\n",
      "Epoch 752/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2093 - accuracy: 0.4651 - val_loss: 1.2028 - val_accuracy: 0.4474\n",
      "Epoch 753/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1982 - accuracy: 0.4630 - val_loss: 1.1947 - val_accuracy: 0.4517\n",
      "Epoch 754/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2025 - accuracy: 0.4659 - val_loss: 1.1803 - val_accuracy: 0.4702\n",
      "Epoch 755/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1938 - accuracy: 0.4666 - val_loss: 1.1926 - val_accuracy: 0.4631\n",
      "Epoch 756/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2031 - accuracy: 0.4676 - val_loss: 1.1836 - val_accuracy: 0.4787\n",
      "Epoch 757/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2155 - accuracy: 0.4627 - val_loss: 1.2160 - val_accuracy: 0.4375\n",
      "Epoch 758/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2112 - accuracy: 0.4623 - val_loss: 1.1885 - val_accuracy: 0.4659\n",
      "Epoch 759/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2019 - accuracy: 0.4612 - val_loss: 1.1861 - val_accuracy: 0.4702\n",
      "Epoch 760/800\n",
      "88/88 [==============================] - 0s 6ms/step - loss: 1.1986 - accuracy: 0.4669 - val_loss: 1.1917 - val_accuracy: 0.4702\n",
      "Epoch 761/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2016 - accuracy: 0.4683 - val_loss: 1.2224 - val_accuracy: 0.4460\n",
      "Epoch 762/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.1942 - accuracy: 0.4630 - val_loss: 1.2508 - val_accuracy: 0.4403\n",
      "Epoch 763/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2005 - accuracy: 0.4598 - val_loss: 1.1817 - val_accuracy: 0.4744\n",
      "Epoch 764/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2042 - accuracy: 0.4641 - val_loss: 1.2202 - val_accuracy: 0.4474\n",
      "Epoch 765/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2197 - accuracy: 0.4587 - val_loss: 1.1915 - val_accuracy: 0.4659\n",
      "Epoch 766/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.1925 - accuracy: 0.4659 - val_loss: 1.1915 - val_accuracy: 0.4560\n",
      "Epoch 767/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2101 - accuracy: 0.4627 - val_loss: 1.1889 - val_accuracy: 0.4574\n",
      "Epoch 768/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2326 - accuracy: 0.4445 - val_loss: 1.1858 - val_accuracy: 0.4744\n",
      "Epoch 769/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2115 - accuracy: 0.4605 - val_loss: 1.1840 - val_accuracy: 0.4688\n",
      "Epoch 770/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2049 - accuracy: 0.4730 - val_loss: 1.1808 - val_accuracy: 0.4815\n",
      "Epoch 771/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2041 - accuracy: 0.4637 - val_loss: 1.1806 - val_accuracy: 0.4688\n",
      "Epoch 772/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.1969 - accuracy: 0.4605 - val_loss: 1.2087 - val_accuracy: 0.4489\n",
      "Epoch 773/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2274 - accuracy: 0.4627 - val_loss: 1.2662 - val_accuracy: 0.4119\n",
      "Epoch 774/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2025 - accuracy: 0.4669 - val_loss: 1.1923 - val_accuracy: 0.4588\n",
      "Epoch 775/800\n",
      "88/88 [==============================] - 1s 10ms/step - loss: 1.2000 - accuracy: 0.4651 - val_loss: 1.1797 - val_accuracy: 0.4744\n",
      "Epoch 776/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1995 - accuracy: 0.4623 - val_loss: 1.2232 - val_accuracy: 0.4375\n",
      "Epoch 777/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1985 - accuracy: 0.4666 - val_loss: 1.1833 - val_accuracy: 0.4773\n",
      "Epoch 778/800\n",
      "88/88 [==============================] - 0s 5ms/step - loss: 1.2001 - accuracy: 0.4563 - val_loss: 1.1996 - val_accuracy: 0.4631\n",
      "Epoch 779/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2079 - accuracy: 0.4630 - val_loss: 1.2040 - val_accuracy: 0.4517\n",
      "Epoch 780/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1936 - accuracy: 0.4680 - val_loss: 1.1923 - val_accuracy: 0.4631\n",
      "Epoch 781/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2713 - accuracy: 0.4179 - val_loss: 1.2712 - val_accuracy: 0.4134\n",
      "Epoch 782/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2887 - accuracy: 0.4150 - val_loss: 1.2669 - val_accuracy: 0.4219\n",
      "Epoch 783/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2861 - accuracy: 0.4143 - val_loss: 1.2658 - val_accuracy: 0.4190\n",
      "Epoch 784/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2806 - accuracy: 0.4104 - val_loss: 1.2508 - val_accuracy: 0.4162\n",
      "Epoch 785/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2510 - accuracy: 0.4289 - val_loss: 1.2033 - val_accuracy: 0.4489\n",
      "Epoch 786/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2124 - accuracy: 0.4637 - val_loss: 1.1881 - val_accuracy: 0.4616\n",
      "Epoch 787/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2018 - accuracy: 0.4630 - val_loss: 1.2399 - val_accuracy: 0.4276\n",
      "Epoch 788/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1953 - accuracy: 0.4716 - val_loss: 1.1799 - val_accuracy: 0.4787\n",
      "Epoch 789/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2277 - accuracy: 0.4523 - val_loss: 1.1951 - val_accuracy: 0.4503\n",
      "Epoch 790/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1950 - accuracy: 0.4748 - val_loss: 1.2471 - val_accuracy: 0.4318\n",
      "Epoch 791/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2509 - accuracy: 0.4353 - val_loss: 1.2661 - val_accuracy: 0.4134\n",
      "Epoch 792/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2125 - accuracy: 0.4705 - val_loss: 1.1828 - val_accuracy: 0.4645\n",
      "Epoch 793/800\n",
      "88/88 [==============================] - 1s 8ms/step - loss: 1.2087 - accuracy: 0.4630 - val_loss: 1.1787 - val_accuracy: 0.4830\n",
      "Epoch 794/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1929 - accuracy: 0.4627 - val_loss: 1.1880 - val_accuracy: 0.4602\n",
      "Epoch 795/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1992 - accuracy: 0.4673 - val_loss: 1.1869 - val_accuracy: 0.4688\n",
      "Epoch 796/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.1950 - accuracy: 0.4716 - val_loss: 1.1863 - val_accuracy: 0.4645\n",
      "Epoch 797/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2192 - accuracy: 0.4481 - val_loss: 1.2320 - val_accuracy: 0.4247\n",
      "Epoch 798/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2124 - accuracy: 0.4545 - val_loss: 1.2722 - val_accuracy: 0.4148\n",
      "Epoch 799/800\n",
      "88/88 [==============================] - 1s 6ms/step - loss: 1.2246 - accuracy: 0.4577 - val_loss: 1.1957 - val_accuracy: 0.4446\n",
      "Epoch 800/800\n",
      "88/88 [==============================] - 1s 7ms/step - loss: 1.2272 - accuracy: 0.4520 - val_loss: 1.1789 - val_accuracy: 0.4759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18625640b50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=800, batch_size=32, validation_split=0.2, callbacks = [back])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 6ms/step - loss: 1.2029 - accuracy: 0.4751\n",
      "Loss: 1.2029025554656982, Accuracy: 0.47511613368988037\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('affective_trained_mlp_475acc.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
